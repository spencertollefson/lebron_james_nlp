{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# timeframe: 2011-02-21 to 2018-09-09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import words\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.sklearn\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import joblib\n",
    "pd.options.display.colheader_justify = 'right'\n",
    "pd.options.display.column_space = 1\n",
    "pd.options.display.expand_frame_repr = True\n",
    "pd.options.display.max_colwidth = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load('data/clean/clean_df.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# don't use stemming with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45671, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>score</th>\n",
       "      <th>author</th>\n",
       "      <th>permalink</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>created_loc</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_score</th>\n",
       "      <th>post_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thats an odd hashtag to throw at the end of this tweet</td>\n",
       "      <td>1085</td>\n",
       "      <td>RajasConCrema</td>\n",
       "      <td>/r/nba/comments/65wmkz/withers_lebron_said_he_couldnt_imagine_losing_a/dgdq1yr/</td>\n",
       "      <td>dgdq1yr</td>\n",
       "      <td>2017-04-18 00:37:33</td>\n",
       "      <td>2017-04-17 16:37:33</td>\n",
       "      <td>[Withers] LeBron said he couldn't imagine losing a sibling like Isaiah Thomas did. \"I can only imagine how that woul...</td>\n",
       "      <td>1398</td>\n",
       "      <td>65wmkz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>that situation is so tough already i cant imagine what it is like preparing all season to get ready for the playoffs...</td>\n",
       "      <td>84</td>\n",
       "      <td>NaN</td>\n",
       "      <td>/r/nba/comments/65wmkz/withers_lebron_said_he_couldnt_imagine_losing_a/dgdpz3b/</td>\n",
       "      <td>dgdpz3b</td>\n",
       "      <td>2017-04-18 00:36:07</td>\n",
       "      <td>2017-04-17 16:36:07</td>\n",
       "      <td>[Withers] LeBron said he couldn't imagine losing a sibling like Isaiah Thomas did. \"I can only imagine how that woul...</td>\n",
       "      <td>1398</td>\n",
       "      <td>65wmkz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i dont think its brought up enough that he never had a sibling or a father figure the fact that hes a great team pla...</td>\n",
       "      <td>209</td>\n",
       "      <td>writingandshit</td>\n",
       "      <td>/r/nba/comments/65wmkz/withers_lebron_said_he_couldnt_imagine_losing_a/dgdsthu/</td>\n",
       "      <td>dgdsthu</td>\n",
       "      <td>2017-04-18 01:28:48</td>\n",
       "      <td>2017-04-17 17:28:48</td>\n",
       "      <td>[Withers] LeBron said he couldn't imagine losing a sibling like Isaiah Thomas did. \"I can only imagine how that woul...</td>\n",
       "      <td>1398</td>\n",
       "      <td>65wmkz</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                      body  \\\n",
       "0                                                                   thats an odd hashtag to throw at the end of this tweet   \n",
       "1  that situation is so tough already i cant imagine what it is like preparing all season to get ready for the playoffs...   \n",
       "2  i dont think its brought up enough that he never had a sibling or a father figure the fact that hes a great team pla...   \n",
       "\n",
       "   score          author  \\\n",
       "0   1085   RajasConCrema   \n",
       "1     84             NaN   \n",
       "2    209  writingandshit   \n",
       "\n",
       "                                                                         permalink  \\\n",
       "0  /r/nba/comments/65wmkz/withers_lebron_said_he_couldnt_imagine_losing_a/dgdq1yr/   \n",
       "1  /r/nba/comments/65wmkz/withers_lebron_said_he_couldnt_imagine_losing_a/dgdpz3b/   \n",
       "2  /r/nba/comments/65wmkz/withers_lebron_said_he_couldnt_imagine_losing_a/dgdsthu/   \n",
       "\n",
       "  comment_id         created_loc         created_utc  \\\n",
       "0    dgdq1yr 2017-04-18 00:37:33 2017-04-17 16:37:33   \n",
       "1    dgdpz3b 2017-04-18 00:36:07 2017-04-17 16:36:07   \n",
       "2    dgdsthu 2017-04-18 01:28:48 2017-04-17 17:28:48   \n",
       "\n",
       "                                                                                                                post_title  \\\n",
       "0  [Withers] LeBron said he couldn't imagine losing a sibling like Isaiah Thomas did. \"I can only imagine how that woul...   \n",
       "1  [Withers] LeBron said he couldn't imagine losing a sibling like Isaiah Thomas did. \"I can only imagine how that woul...   \n",
       "2  [Withers] LeBron said he couldn't imagine losing a sibling like Isaiah Thomas did. \"I can only imagine how that woul...   \n",
       "\n",
       "   post_score post_id  \n",
       "0        1398  65wmkz  \n",
       "1        1398  65wmkz  \n",
       "2        1398  65wmkz  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Properly do entire data set and a train_test_split later on\n",
    "df_small = df[:20000]\n",
    "\n",
    "df_small_train = df_small[:int(0.7 * df_small.shape[0])]\n",
    "df_small_test = df_small[int(0.7 * df_small.shape[0]):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cv= CountVectorizer(min_df = 10, max_df = .99, #ngram_range=(1, 2),\n",
    "                         strip_accents='ascii',\n",
    "                     strip_accents='unicode', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_tf = test_cv.fit_transform(df.body)\n",
    "most_common_df = pd.DataFrame(dtm_tf.toarray(), columns=test_cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    32504\n",
       "True     13167\n",
       "Name: body, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.body.str.contains('lebron').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the              41729\n",
       "to               22576\n",
       "and              19010\n",
       "lebron           15172\n",
       "is               14893\n",
       "he               14514\n",
       "in               14017\n",
       "of               13472\n",
       "that             12294\n",
       "this             10117\n",
       "it                9154\n",
       "for               8322\n",
       "his               7730\n",
       "on                7698\n",
       "was               7551\n",
       "you               6337\n",
       "be                6107\n",
       "but               5796\n",
       "with              5769\n",
       "like              5581\n",
       "just              4966\n",
       "him               4852\n",
       "not               4626\n",
       "have              4571\n",
       "at                4498\n",
       "if                4440\n",
       "as                4350\n",
       "all               4347\n",
       "game              4196\n",
       "so                4134\n",
       "                 ...  \n",
       "memorable           10\n",
       "opens               10\n",
       "busy                10\n",
       "butthurt            10\n",
       "arsenal             10\n",
       "obama               10\n",
       "neutral             10\n",
       "stellar             10\n",
       "nailed              10\n",
       "moon                10\n",
       "stink               10\n",
       "mismatch            10\n",
       "minority            10\n",
       "metrics             10\n",
       "medal               10\n",
       "lethal              10\n",
       "struck              10\n",
       "appeal              10\n",
       "stud                10\n",
       "mastered            10\n",
       "martin              10\n",
       "ludicrous           10\n",
       "suffering           10\n",
       "logical             10\n",
       "sums                10\n",
       "lockout             10\n",
       "livelaughlove       10\n",
       "lip                 10\n",
       "chaos               10\n",
       "zoom                10\n",
       "Length: 4793, dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_common_df.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_ngrams(self, tokens): #, stop_words=None):\n",
    "    \"\"\"Turn tokens into a sequence of n-grams after stop words filtering\"\"\"\n",
    "    # handle stop words\n",
    "#     if stop_words is not None:\n",
    "#         tokens = [w for w in tokens if w not in stop_words]\n",
    "\n",
    "    # handle token n-grams\n",
    "    min_n, max_n = self.ngram_range\n",
    "    if max_n != 1:\n",
    "        original_tokens = tokens\n",
    "        if min_n == 1:\n",
    "            # no need to do any slicing for unigrams\n",
    "            # just iterate through the original tokens\n",
    "            tokens = list(original_tokens)\n",
    "            min_n += 1\n",
    "        else:\n",
    "            tokens = []\n",
    "\n",
    "        n_original_tokens = len(original_tokens)\n",
    "\n",
    "        # bind method outside of loop to reduce overhead\n",
    "        tokens_append = tokens.append\n",
    "        space_join = \" \".join\n",
    "\n",
    "        for n in xrange(min_n,\n",
    "                        min(max_n + 1, n_original_tokens + 1)):\n",
    "            for i in xrange(n_original_tokens - n + 1):\n",
    "                tokens_append(space_join(original_tokens[i: i + n]))\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next steps:\n",
    "1. I want to find the X topics/clusters about these texts. Perhaps it's fitness, politics, training, performance, GOAT.\n",
    "2. Figure out which topic each document best corresponds to, and place the document within that topic/cluster\n",
    "3. Chart a stacked-bar or a multi-line chart for each year (or month, or something else) from 2011-2018, and show\n",
    "   the PERCENTAGE (Or COUNT) of each topic for that period of time.\n",
    "4. Look at the insights! What does that mean?\n",
    "5. Perhaps do sentiment analysis. See if I can find a well-trained model. Or train my own based on upvote? score? (Probably not doing this)\n",
    "\n",
    "**NOTE**: Simply do LDA first, and make this work. Get a chart. Get some insights.\n",
    "**THEN:** Make it repeatable. Get it in a function somehow. Try other Dim Red and Unclassifying and Topic modeling techniques. See what works best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_corpus = set(words.words())\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "stem = SnowballStemmer('english')\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "stops += ['just', 'lol', 'like', 'im', 'he', 'hes', 'would', 'get', 'going', 'doesnt', 'th', 'fuck', 'think', 'even', 'dont',\n",
    "    'lebron', 'james', 'game', 'didnt', 'cant', 'say', 'see', 'look', 'go', 'said', 'also']\n",
    "stops = set(stops)\n",
    "acceptable_words = words_corpus - stops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current isues:\n",
    "* can't use stemmer and n_grams at same time.\n",
    "* still too many junk words, even with growing stop_list\n",
    "* better stop word list. perhaps from reddit.\n",
    "* what is max_features?\n",
    "* **don't have a lemmatizer in there. How can i do lemmatize, n_grams, stop words, and stemmer all in analyer?**\n",
    "\n",
    "### Tell Roberto/Chad I'm having a real hard time cleaning my text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42862"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordpunct = nltk.WordPunctTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pos = nltk.pos_tag(wordpunct.tokenize('filthy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('filthy', 'NN')]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NN'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pos[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'adj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-195-9f25b127f1b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'filthy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adj'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/corpus/reader/wordnet.py\u001b[0m in \u001b[0;36m_morphy\u001b[0;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;31m#    find a match or you can't go any further\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1774\u001b[0;31m         \u001b[0mexceptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1775\u001b[0m         \u001b[0msubstitutions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMORPHOLOGICAL_SUBSTITUTIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'adj'"
     ]
    }
   ],
   "source": [
    "lemmatizer.lemmatize('filthy', pos='adj')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-176-3dea2ce487d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrythis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordpunct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_small_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/nltk/tokenize/regexp.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;31m# If our regexp matches tokens, use re.findall:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "trythis = wordpunct.tokenize(df_small_train.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencer/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:286: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens [\"'d\", \"'ll\", \"'re\", \"'s\", \"'ve\", 'could', 'might', 'must', \"n't\", 'need', 'sha', 'wo'] not in stop_words.\n",
      "  sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14000, 3546)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_gram_size = 2\n",
    "\n",
    "def english_corpus(doc, stemmer=stem):\n",
    "    clean_words = [stemmer.stem(w) for w in analyzer(doc) if w in acceptable_words]\n",
    "#     num_index = 0\n",
    "#     for w in clean_words:\n",
    "#         yield w\n",
    "#         try:\n",
    "#             if clean_words[num_index + 1]:\n",
    "#                 yield clean_words[num_index + 1]\n",
    "#         except:\n",
    "#             continue\n",
    "#         num_index+= 1    \n",
    "    return [stemmer.stem(w) for w in analyzer(doc) if w in acceptable_words]\n",
    "\n",
    "cv = CountVectorizer(stop_words=stops, \n",
    "                     #analyzer=english_corpus, \n",
    "                     min_df = 3, max_df = .95, ngram_range=(n_gram_size, n_gram_size),\n",
    "                     strip_accents='unicode', \n",
    "                     encoding='utf-8',\n",
    "                     tokenizer=TreebankWordTokenizer().tokenize,\n",
    "                     #max_features=100\n",
    "                    )\n",
    "dtm_tf = cv.fit_transform(df_small_train.body)\n",
    "dtm_tf.shape\n",
    "\n",
    "\n",
    "# def words_and_char_bigrams(text):\n",
    "# ...     words = re.findall(r'\\w{3,}', text)\n",
    "# ...     for w in words:\n",
    "# ...         yield w\n",
    "# ...         for i in range(len(w) - 2):\n",
    "# ...             yield w[i:i+2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::::\n",
      "Number of topics = 3\n",
      ":::::\n",
      "TOPIC 0\n",
      "gon na\n",
      "r nba\n",
      "triple double\n",
      "high school\n",
      "got ta\n",
      "locker room\n",
      "free throw\n",
      "\n",
      "TOPIC 1\n",
      "best player\n",
      "kevin love\n",
      "holy shit\n",
      "basketball player\n",
      "anyone else\n",
      "years ago\n",
      "ty lue\n",
      "\n",
      "TOPIC 2\n",
      "last year\n",
      "regular season\n",
      "year old\n",
      "ever seen\n",
      "ive ever\n",
      "k k\n",
      "ive seen\n",
      "\n",
      ":::::\n",
      "Number of topics = 4\n",
      ":::::\n",
      "TOPIC 0\n",
      "gon na\n",
      "triple double\n",
      "got ta\n",
      "locker room\n",
      "wan na\n",
      "last night\n",
      "pretty sure\n",
      "\n",
      "TOPIC 1\n",
      "best player\n",
      "kevin love\n",
      "next year\n",
      "holy shit\n",
      "anyone else\n",
      "basketball player\n",
      "ty lue\n",
      "\n",
      "TOPIC 2\n",
      "gon na\n",
      "last year\n",
      "regular season\n",
      "ever seen\n",
      "ive ever\n",
      "year old\n",
      "k k\n",
      "\n",
      "TOPIC 3\n",
      "r nba\n",
      "high school\n",
      "every time\n",
      "free throw\n",
      "ive seen\n",
      "space jam\n",
      "cavs fans\n",
      "\n",
      ":::::\n",
      "Number of topics = 5\n",
      ":::::\n",
      "TOPIC 0\n",
      "gon na\n",
      "triple double\n",
      "ever seen\n",
      "ive ever\n",
      "paul george\n",
      "pretty sure\n",
      "jr smith\n",
      "\n",
      "TOPIC 1\n",
      "best player\n",
      "next year\n",
      "holy shit\n",
      "anyone else\n",
      "god damn\n",
      "player league\n",
      "really good\n",
      "\n",
      "TOPIC 2\n",
      "gon na\n",
      "regular season\n",
      "last year\n",
      "year old\n",
      "k k\n",
      "averaged ppg\n",
      "free throws\n",
      "\n",
      "TOPIC 3\n",
      "r nba\n",
      "every time\n",
      "free throw\n",
      "ive seen\n",
      "high school\n",
      "space jam\n",
      "everyone else\n",
      "\n",
      "TOPIC 4\n",
      "got ta\n",
      "kevin love\n",
      "ty lue\n",
      "skip bayless\n",
      "one best\n",
      "wan na\n",
      "last night\n",
      "\n",
      ":::::\n",
      "Number of topics = 6\n",
      ":::::\n",
      "TOPIC 0\n",
      "gon na\n",
      "high school\n",
      "locker room\n",
      "golden state\n",
      "paul george\n",
      "rebounds assists\n",
      "pretty good\n",
      "\n",
      "TOPIC 1\n",
      "best player\n",
      "holy shit\n",
      "anyone else\n",
      "god damn\n",
      "pretty much\n",
      "basketball player\n",
      "really good\n",
      "\n",
      "TOPIC 2\n",
      "triple double\n",
      "ever seen\n",
      "year old\n",
      "ive ever\n",
      "k k\n",
      "every year\n",
      "free throws\n",
      "\n",
      "TOPIC 3\n",
      "r nba\n",
      "every time\n",
      "free throw\n",
      "ive seen\n",
      "space jam\n",
      "triple doubles\n",
      "everyone else\n",
      "\n",
      "TOPIC 4\n",
      "got ta\n",
      "ty lue\n",
      "skip bayless\n",
      "regular season\n",
      "much better\n",
      "years ago\n",
      "thats pretty\n",
      "\n",
      "TOPIC 5\n",
      "last year\n",
      "kevin love\n",
      "next year\n",
      "last season\n",
      "averaged ppg\n",
      "pretty sure\n",
      "jr smith\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-215-7ed771e66d53>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn_topic\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloop_lda_tf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLatentDirichletAllocation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloop_lda_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtm_tf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m':::::'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Number of topics = {n_topic}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0;31m# batch update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                     self._em_step(X, total_samples=n_samples,\n\u001b[0;32m--> 570\u001b[0;31m                                   batch_update=True, parallel=parallel)\n\u001b[0m\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m                 \u001b[0;31m# check perplexity\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py\u001b[0m in \u001b[0;36m_em_step\u001b[0;34m(self, X, total_samples, batch_update, parallel)\u001b[0m\n\u001b[1;32m    451\u001b[0m         \u001b[0;31m# E-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m         _, suff_stats = self._e_step(X, cal_sstats=True, random_init=True,\n\u001b[0;32m--> 453\u001b[0;31m                                      parallel=parallel)\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# M-step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py\u001b[0m in \u001b[0;36m_e_step\u001b[0;34m(self, X, cal_sstats, random_init, parallel)\u001b[0m\n\u001b[1;32m    404\u001b[0m                                               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_change_tol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcal_sstats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                                               random_state)\n\u001b[0;32m--> 406\u001b[0;31m             for idx_slice in gen_even_slices(X.shape[0], n_jobs))\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# merge result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    981\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    823\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    826\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 261\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    262\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py\u001b[0m in \u001b[0;36m_update_doc_distribution\u001b[0;34m(X, exp_topic_word_distr, doc_topic_prior, max_iters, mean_change_tol, cal_sstats, random_state)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;31m# The next one is a copy, since the inner loop overwrites it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0mexp_doc_topic_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_doc_topic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0mexp_topic_word_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_topic_word_distr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;31m# Iterate between `doc_topic_d` and `norm_phi` until convergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# pd.DataFrame(dtm_tf.toarray(), columns=cv.get_feature_names()).shape\n",
    "\n",
    "# lda_tf = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "# lda_tf.fit(dtm_tf)\n",
    "\n",
    "# # pyLDAvis.sklearn.prepare(lda_tf, dtm_tf, cv)\n",
    "# see_lda_topics(cv, 5, lda_tf, 7)\n",
    "\n",
    "for n_topic in range(3,10):\n",
    "    loop_lda_tf = LatentDirichletAllocation(n_components=n_topic, random_state=0)\n",
    "    loop_lda_tf.fit(dtm_tf)\n",
    "    print(':::::')\n",
    "    print(f'Number of topics = {n_topic}')\n",
    "    print(':::::')\n",
    "    see_lda_topics(cv, n_topic, loop_lda_tf, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spencer/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:1547: UserWarning: Only (<class 'numpy.float64'>, <class 'numpy.float32'>, <class 'numpy.float16'>) 'dtype' should be used. <class 'numpy.int64'> 'dtype' will be converted to np.float64.\n",
      "  UserWarning)\n",
      "/home/spencer/anaconda3/lib/python3.6/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el20901401097801558728007375358\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el20901401097801558728007375358_data = {\"mdsDat\": {\"x\": [-0.051492744707994725, -0.06834156445979697, -0.035743151824721535, -0.07037725843411621, -0.08287395134779309, 0.08996688698647777, -0.0025568698822596055, 0.08276788163951945, -0.0014953255285253813, 0.14014609755921037], \"y\": [-0.005655537286592116, 0.014100930072370574, -0.013698615849413695, -0.058974622669656286, -0.050362647415795984, 0.041092540315857934, 0.1294108709759792, 0.09207354640156239, -0.011377440474972389, -0.13660902406933983], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [17.89166692455283, 13.069484078592014, 9.888963178348927, 9.431428075014917, 9.166373468938732, 8.382240802449417, 8.372704103420347, 8.316883745054064, 8.013486989759036, 7.466768633869714]}, \"tinfo\": {\"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"Freq\": [34.0, 33.0, 46.0, 22.0, 20.0, 18.0, 65.0, 16.0, 24.0, 42.0, 20.0, 26.0, 14.0, 65.0, 15.0, 54.0, 18.0, 15.0, 43.0, 15.0, 25.0, 27.0, 14.0, 16.0, 28.0, 24.0, 23.0, 17.0, 15.0, 11.0, 6.6800033375062755, 10.815179455112741, 8.336324360064083, 4.3537168619370235, 10.573538153980536, 3.963874002645304, 12.897683696467016, 3.8909373255472084, 15.689780656716719, 4.285256452481121, 3.216260847988138, 8.467576584777115, 3.141567480839053, 5.088911013213604, 4.332355295940703, 5.647665687073012, 3.898923260909319, 2.9199382976454333, 2.8950477541896453, 4.403739655153905, 2.8209910828292157, 7.3635891313145425, 2.4480488606096693, 3.115852011695315, 13.12285616924268, 3.9222202663582966, 2.235263126381747, 2.216881637596623, 6.005639447093295, 3.9622634574778566, 3.2660441208785693, 32.049922469419265, 9.683856328974075, 5.342702597867433, 32.11405734209462, 16.696042013950237, 15.782891610528871, 6.374098518507173, 10.739117135932956, 23.420007784994922, 26.15081509173813, 27.591715539254672, 16.071684243093564, 15.122625655968491, 19.206655488181248, 15.083403856439427, 11.718704464637804, 17.89410238369081, 9.593532417189175, 25.582677673213293, 24.475795626627068, 11.151930045745633, 8.350357998531488, 20.04614757256558, 23.981940790675488, 16.362640613775344, 13.68433621431568, 18.69402300005328, 15.990280389010167, 14.078539007509333, 13.992290293549294, 13.646910829809729, 13.987692651941886, 13.016191562008352, 11.64900669299545, 11.987646622408116, 12.338677887259827, 5.763341078907728, 6.693201399439977, 4.634848288701602, 13.613190310481059, 5.296656771166446, 3.9692536764971162, 7.282994873098853, 3.2772345509538097, 4.02222022923937, 3.136067296681887, 2.7987513212446116, 11.218250119476474, 6.546005733235594, 2.5756600385750685, 3.918497846746494, 4.436885064144098, 2.317642696052768, 5.170857019934, 2.2880297290481506, 3.366970689444772, 2.209893760736323, 2.191271350502092, 2.1138079342703344, 3.5238869054967004, 2.0842232178921622, 2.75419147604433, 2.9410316660519764, 1.960865891202002, 10.381177701936673, 2.673352076439911, 4.468789462646446, 8.601173502701839, 12.204416795876483, 6.882515809709893, 18.10629261585323, 9.607603291688365, 3.639639624749526, 4.619270144383348, 15.983096263560984, 4.0767769069155975, 15.315069437762935, 6.391802626929272, 8.801107196600164, 17.144165284242835, 9.410951136696408, 10.631522204966183, 9.360367586986088, 9.21971990884414, 12.357664636505326, 20.984322427981166, 20.246936270950407, 14.420031315538711, 8.499442835833477, 9.742136246098884, 19.587498638671352, 11.846027709519054, 7.999142503612869, 11.775992827728263, 19.22174950235048, 13.42566527900243, 10.030633959741488, 11.12828418609571, 10.73981054881632, 11.002926524148915, 12.452083286486811, 10.716650600898781, 9.28165051852342, 7.35158482754117, 7.043886219050814, 5.285560112283432, 4.845684612061235, 10.023776346482592, 4.585817112342595, 4.038136278226484, 3.742464671466321, 7.112140306989632, 4.2581360492521565, 3.0054374509449464, 2.9212726218155707, 2.8962587892200675, 2.6751243799423783, 2.6733976437317715, 2.6164578179220253, 2.4544727720774198, 2.3632287300060706, 4.4487441326318855, 2.325153917748355, 2.322076314579373, 4.350632156671586, 3.8788019035574575, 2.181528590163311, 2.0609972222077135, 2.954475599291012, 2.041566226884744, 1.9812015522111917, 1.9089160889466978, 1.8863777841834668, 5.793705451401569, 3.6324075951272303, 8.660363590985265, 4.30718497640725, 4.750835828915464, 31.442709254250406, 13.215238144099064, 5.868357867940591, 7.090443694272991, 3.900668386567167, 9.983905858168987, 11.036657577910805, 11.334622958034345, 14.514856283896235, 7.481273716885603, 7.8935321104253, 6.403420775426014, 11.220561690376407, 6.6345274490446275, 10.877843645154755, 8.843811413414517, 8.249055912431961, 8.698038931880859, 10.123491497612747, 9.237276149856136, 7.430411157557299, 7.308998646799885, 7.717444940455286, 6.778417853188295, 7.2175819778854455, 6.460436504467506, 6.448079543083382, 9.455330394041118, 6.336303627333876, 28.253236309809342, 4.173982999439873, 12.749330537394771, 3.840526230519842, 4.740227089970228, 4.643721556363316, 4.081616492002156, 3.006801053004554, 3.449049978171783, 4.974673200321968, 6.316956365696461, 2.7748196297683863, 4.351199983709936, 5.908704136960131, 2.557309047912825, 3.056847175329718, 3.9020321244587457, 3.228366050004312, 2.250819225476587, 5.035269567985253, 2.481565390196048, 2.002581818696757, 4.369310819922278, 1.927017745754321, 2.3736291995098755, 1.9150505869665568, 1.8996383989897359, 3.7218210847140303, 8.256242812327551, 5.9984624678037415, 12.410884419362814, 2.9680642096641194, 3.9549043743090566, 19.359292521379135, 9.259646078717601, 10.575042278243055, 7.505998860733953, 18.427635143391843, 25.092273243114395, 6.142979743190798, 4.999664846056885, 10.3392190493343, 8.212746768193348, 12.90930387474146, 9.917764698001815, 10.295381995466316, 8.84252822457015, 10.358104720005976, 6.866377303151481, 7.462229724288865, 8.238054957037845, 7.449820748589441, 6.72676093686422, 6.022631763814108, 5.579136338277927, 6.174762145185255, 13.502806317126243, 5.113791347505627, 5.080214880028119, 6.384362653621663, 4.477595355265213, 9.275350584077476, 3.856841491035531, 8.665461605071178, 2.8026882103891126, 2.7476082546401166, 9.168352603873231, 2.5953311673835757, 5.628907809540788, 6.247565776588676, 4.520873306713804, 2.3889454160405093, 3.3840150407577383, 2.2779363183728143, 2.24922877147961, 3.006070116864627, 5.917018047840816, 2.098159251705468, 3.3792970504905444, 3.120856829800204, 3.7273424577962815, 2.1718292730177193, 6.999379302325557, 2.6332195614826617, 8.382840610200322, 2.8050674967895652, 4.589139644402326, 4.422835713630676, 5.319217517849646, 9.57893295241805, 11.169192264355374, 6.992004018022983, 21.17301910808688, 12.098892706118717, 9.816830206075013, 6.974247763958207, 5.754080034260948, 7.598010388650244, 5.394394772977002, 5.568123442236268, 14.043690013986447, 7.234521123252458, 8.560553632807943, 7.169392149927194, 10.106546980263856, 6.445112408133332, 11.29359289183613, 9.070777410099154, 5.681301784440318, 5.722218689515804, 6.9277868708010315, 5.960655286502782, 6.403706403868951, 6.155927855659717, 5.914040992678955, 17.155631485382646, 6.942427580240892, 7.78317585655137, 4.486586083345449, 4.365004364854677, 5.333803102194831, 3.7971968751366476, 3.425406641370742, 3.1846128220278604, 2.96501518460069, 4.877882140780005, 2.65759124735604, 2.329776526202931, 2.668216526848866, 2.81564322572632, 4.6802167092515345, 2.1150927113501297, 3.776763441478475, 6.6539520756564166, 1.8465002946258746, 1.845274812762319, 4.849745691990715, 5.032517824591199, 1.7781647735756423, 5.342477735581439, 1.6927698731731224, 1.6852891002408306, 1.6577923802867374, 4.118462286409741, 1.7478902555171112, 6.930910508603678, 8.873544871474053, 3.2343828482056978, 5.0669796876226245, 8.73061190830543, 7.342689736348745, 3.7756529069276565, 8.587480685389183, 7.198150494016195, 6.238403999394401, 9.27907514216051, 10.285149088255858, 10.753737656478389, 8.050688123097638, 9.178928403459105, 7.227368652013756, 11.073002494082997, 5.58772558015075, 8.258871840149771, 11.130093838407142, 8.253653182891622, 6.858114779285738, 7.629482497850201, 7.7770871368985635, 6.434425894802398, 5.323812374621671, 5.518140518090069, 6.136455648575734, 5.886933873569523, 5.870324283267573, 5.574333212126383, 19.12051765546451, 10.013232548465696, 7.012006661021317, 3.662802471609098, 5.102624028923938, 3.3091847132873218, 12.09946612007919, 2.5224981457868125, 5.730476441491406, 3.5468282842021326, 2.3291587190989618, 10.89211424177956, 2.214539938894706, 2.0796062191238516, 2.0725435069401934, 2.391680141006569, 1.9151650444008441, 2.4620588639365795, 4.142808579906726, 3.0749937411264407, 1.8068090392083487, 2.2392292681333803, 16.639361216028338, 3.4080261149548297, 6.076990770634062, 1.6388564223573807, 4.218135809170162, 4.782697427947178, 1.8192263357361749, 1.5074570580301772, 5.20671096211334, 4.1947817959699405, 8.064199213250793, 6.227685101682034, 8.137441141930115, 4.898532525123612, 4.124434878818982, 4.07843542667682, 5.885103532363198, 7.7910234325543435, 5.039983174826876, 13.354496435999096, 10.810419190397468, 9.651975771714634, 16.166512405055247, 5.057473226784548, 8.859726662457176, 8.192104706977156, 7.542696120424305, 10.142675633424183, 7.252128763491794, 10.728970799124493, 6.090070992848744, 6.176851836928206, 9.378567257000501, 6.900412418034228, 5.988016165167735, 5.607285525206588, 5.317215415489121, 5.408084493355023, 5.251715988105742, 6.17678997882645, 4.717679196368585, 9.536435207667546, 6.5348366559310405, 28.047350778076563, 4.252936171367907, 4.173263845969978, 3.2370280413936476, 2.78185143166767, 2.7420439794452207, 2.7127814384378013, 5.5391963832839215, 2.493049543535945, 2.8597342264156187, 2.316091549278624, 5.12981190625136, 2.2507911882053664, 4.0587773226791395, 2.1728566948337185, 2.919532805793068, 2.0982966786041537, 2.072835319329475, 3.840345331249758, 5.475734524561192, 2.967143579952766, 2.3917709112080914, 1.84768487395656, 1.828704798978872, 2.273318999447987, 3.4038394263733633, 4.7585394682439155, 25.018503547870896, 7.8954210213204075, 13.81366205844112, 9.14639351956004, 3.9216905745037343, 5.0904405436114715, 6.315805188438822, 22.73573677769415, 6.162171338064973, 7.658301458989907, 11.351847346747817, 8.452212640762074, 7.728293607239943, 4.78427467571198, 5.641009448549262, 12.916223805906348, 7.795059941846837, 10.029597945691663, 9.044317186555654, 6.580890367119145, 7.246874514874047, 6.1245768334782555, 8.007332290437011, 6.086370482242298, 6.133420462979614, 5.826143246989565, 5.664325348786493, 5.557356337280624, 7.621360607358844, 7.444571347131982, 6.447892550047101, 4.269226797287847, 3.9879756325196962, 3.7900008113499744, 4.028932881711154, 2.9396095707584267, 2.66908412777724, 2.475391437559401, 15.632943661029074, 2.1924418771765595, 5.595888651664538, 3.9939938696014483, 2.3187613697487652, 2.036291653269935, 6.394549921122943, 2.300323051315235, 1.881311216788542, 3.5513097413772043, 1.729049985634894, 1.7228773327219022, 2.845764834293175, 1.7088262947978257, 1.7076933702077859, 2.260552353343223, 3.0649979635185525, 3.897118823505713, 5.582631762169752, 1.5595252225093037, 5.905607146838186, 11.927578114831283, 2.8922245605834944, 6.183494468354905, 4.279774784378932, 19.468852138652917, 10.302188443448035, 12.000434061113571, 6.694502907464356, 5.723758159581762, 15.54973183311472, 5.388213364578035, 4.532180588818038, 7.308928187423556, 6.168507499698494, 5.4759575455129434, 6.058249319278034, 9.184604505968471, 6.9034411923498675, 7.194102350506157, 6.74913968816662, 6.365709656392855, 5.721014930054077, 5.235680831385413, 5.138575341730204, 5.763614722670286, 5.98857784046134, 5.478225520952256, 15.120367174258392, 13.278847746760501, 6.326215663649689, 6.065955274530961, 18.790367553239015, 3.931973848869855, 3.9610227880165496, 4.524059669977538, 3.552456546957014, 3.2675877678117624, 4.197166736928632, 3.027732530650763, 4.508584900679373, 2.641869538806213, 2.8057254026566376, 5.369478073057793, 3.978775484094381, 8.289398111254757, 2.3004871096364052, 2.299014519877827, 5.294645526951408, 2.2083116897053463, 2.206636299517313, 4.514794566384793, 2.1075293297576474, 1.9881852684537376, 1.8922578417197744, 1.8363256519543534, 1.772000248198676, 2.239006652724864, 6.359970750314796, 10.10095560231213, 5.5878353280571265, 3.5321034384244006, 3.9697503116252753, 9.606735881007783, 11.90311898082983, 6.523185843935048, 3.7745298341238374, 5.995097852809257, 4.452740276033352, 4.457640308793299, 10.888165002282365, 4.66565364352158, 4.447924706931814, 5.365000807383495, 6.928209901778192, 7.846342412789477, 7.264154072381892, 4.775657125300277, 4.606635666354524, 5.865623024676237, 4.801877372208919, 5.129754903138357, 4.971870757775013, 4.740846293511956, 4.7096503833183645], \"Term\": [\"nice\", \"confirm\", \"damn\", \"doubl\", \"king\", \"miss\", \"man\", \"tripl\", \"magic\", \"right\", \"oh\", \"god\", \"tho\", \"love\", \"million\", \"season\", \"question\", \"regular\", \"guy\", \"trade\", \"coach\", \"pass\", \"record\", \"respect\", \"call\", \"mean\", \"anyon\", \"lanc\", \"today\", \"ad\", \"agre\", \"worst\", \"gone\", \"casual\", \"either\", \"discuss\", \"liter\", \"system\", \"us\", \"skill\", \"toni\", \"histori\", \"parker\", \"dan\", \"process\", \"effici\", \"compar\", \"simpl\", \"unstopp\", \"trash\", \"sudden\", \"step\", \"offic\", \"shoulder\", \"happen\", \"quot\", \"fam\", \"dis\", \"may\", \"trust\", \"em\", \"best\", \"world\", \"sub\", \"play\", \"score\", \"put\", \"like\", \"final\", \"ever\", \"back\", \"player\", \"leagu\", \"point\", \"never\", \"give\", \"mani\", \"go\", \"absolut\", \"team\", \"think\", \"seen\", \"knew\", \"dont\", \"game\", \"see\", \"come\", \"one\", \"even\", \"take\", \"know\", \"peopl\", \"year\", \"still\", \"top\", \"didnt\", \"time\", \"insid\", \"deep\", \"immedi\", \"today\", \"jimmi\", \"incom\", \"later\", \"angri\", \"suck\", \"elbow\", \"awkward\", \"stay\", \"hurt\", \"meanwhil\", \"contest\", \"press\", \"elimin\", \"legaci\", \"aspect\", \"sick\", \"terri\", \"risk\", \"wast\", \"dick\", \"key\", \"class\", \"ben\", \"undef\", \"block\", \"crack\", \"handl\", \"laugh\", \"dunk\", \"line\", \"pass\", \"yes\", \"ref\", \"paint\", \"call\", \"pull\", \"day\", \"care\", \"theyr\", \"ball\", \"face\", \"goat\", \"serious\", \"durant\", \"old\", \"year\", \"see\", \"jordan\", \"bosh\", \"real\", \"good\", \"shot\", \"per\", \"get\", \"game\", \"realli\", \"two\", \"last\", \"also\", \"look\", \"time\", \"one\", \"peopl\", \"jam\", \"blow\", \"correct\", \"replay\", \"space\", \"ear\", \"danc\", \"shape\", \"joke\", \"forgot\", \"unguard\", \"bar\", \"lin\", \"commentari\", \"share\", \"eh\", \"shook\", \"rule\", \"check\", \"page\", \"breath\", \"yesterday\", \"hire\", \"hour\", \"exagger\", \"realiti\", \"grade\", \"parti\", \"releas\", \"unit\", \"matter\", \"recruit\", \"bird\", \"write\", \"famili\", \"man\", \"coach\", \"sad\", \"help\", \"tire\", \"lue\", \"feel\", \"bad\", \"watch\", \"head\", \"cool\", \"life\", \"actual\", \"rememb\", \"better\", \"alway\", \"thing\", \"basketbal\", \"dont\", \"time\", \"make\", \"say\", \"think\", \"need\", \"one\", \"ball\", \"good\", \"mike\", \"griffin\", \"confirm\", \"dirti\", \"trade\", \"woke\", \"locker\", \"brown\", \"journal\", \"miller\", \"visit\", \"support\", \"room\", \"headband\", \"chill\", \"father\", \"prepar\", \"treatment\", \"found\", \"narrat\", \"math\", \"third\", \"offer\", \"glorious\", \"job\", \"potato\", \"cramp\", \"imag\", \"lit\", \"qualiti\", \"larri\", \"boston\", \"new\", \"cast\", \"train\", \"guy\", \"almost\", \"hate\", \"video\", \"season\", \"game\", \"full\", \"five\", \"next\", \"curri\", \"got\", \"wade\", \"great\", \"dude\", \"good\", \"work\", \"way\", \"think\", \"realli\", \"player\", \"heat\", \"went\", \"time\", \"million\", \"hart\", \"welcom\", \"terribl\", \"attent\", \"contract\", \"eastern\", \"deal\", \"commission\", \"date\", \"draft\", \"younger\", \"rich\", \"cours\", \"field\", \"dun\", \"select\", \"classic\", \"dog\", \"exampl\", \"worth\", \"turner\", \"citi\", \"passer\", \"franchis\", \"thus\", \"pleas\", \"brother\", \"funni\", \"fals\", \"listen\", \"til\", \"rather\", \"holi\", \"pick\", \"sign\", \"that\", \"big\", \"keep\", \"prime\", \"retir\", \"second\", \"place\", \"exact\", \"say\", \"away\", \"alreadi\", \"ridicul\", \"take\", \"what\", \"one\", \"time\", \"guess\", \"read\", \"team\", \"insan\", \"dont\", \"also\", \"game\", \"miss\", \"duo\", \"reaction\", \"shame\", \"anim\", \"motiv\", \"footbal\", \"appar\", \"derrick\", \"nephew\", \"link\", \"icon\", \"blown\", \"analysi\", \"die\", \"chemistri\", \"pant\", \"smile\", \"hous\", \"manag\", \"subscrib\", \"streak\", \"yo\", \"mission\", \"biggest\", \"appropri\", \"begun\", \"dray\", \"injur\", \"epic\", \"dribbl\", \"decis\", \"format\", \"earli\", \"break\", \"thread\", \"touch\", \"beat\", \"took\", \"pop\", \"yeah\", \"someon\", \"sure\", \"believ\", \"wait\", \"noth\", \"could\", \"interest\", \"top\", \"team\", \"cant\", \"everyon\", \"everi\", \"time\", \"great\", \"shut\", \"without\", \"even\", \"see\", \"player\", \"someth\", \"king\", \"ad\", \"poor\", \"worri\", \"longer\", \"death\", \"regular\", \"outlet\", \"white\", \"origin\", \"light\", \"record\", \"remov\", \"lord\", \"yep\", \"highest\", \"chose\", \"backward\", \"ya\", \"club\", \"crown\", \"joey\", \"magic\", \"anybodi\", \"week\", \"blood\", \"situat\", \"join\", \"seat\", \"tight\", \"readi\", \"somebodi\", \"hey\", \"school\", \"thank\", \"dumb\", \"anyway\", \"twitter\", \"athlet\", \"leav\", \"sens\", \"look\", \"probabl\", \"shoot\", \"one\", \"wish\", \"post\", \"end\", \"hell\", \"season\", \"crazi\", \"time\", \"straight\", \"edit\", \"game\", \"even\", \"got\", \"love\", \"god\", \"booker\", \"princ\", \"boy\", \"scrub\", \"skip\", \"jersey\", \"nice\", \"dame\", \"nation\", \"luck\", \"compet\", \"wet\", \"luke\", \"dream\", \"beach\", \"flip\", \"hammer\", \"legend\", \"afford\", \"tall\", \"booti\", \"buy\", \"updat\", \"pretend\", \"till\", \"drop\", \"agenc\", \"anywher\", \"handshak\", \"anthem\", \"planet\", \"hair\", \"word\", \"damn\", \"money\", \"god\", \"foul\", \"babi\", \"act\", \"impress\", \"love\", \"chanc\", \"list\", \"harden\", \"id\", \"tell\", \"number\", \"dirk\", \"still\", \"thought\", \"said\", \"good\", \"star\", \"win\", \"imagin\", \"man\", \"talk\", \"say\", \"dont\", \"much\", \"time\", \"nasti\", \"angl\", \"cute\", \"celebr\", \"regard\", \"trip\", \"hairlin\", \"puppet\", \"fish\", \"cole\", \"oh\", \"bowl\", \"bum\", \"unreal\", \"trigger\", \"threw\", \"assist\", \"lob\", \"touchdown\", \"remind\", \"judg\", \"memori\", \"girl\", \"repli\", \"shake\", \"screen\", \"statement\", \"bout\", \"form\", \"halfway\", \"doubt\", \"question\", \"realist\", \"guard\", \"bunch\", \"right\", \"fun\", \"mean\", \"name\", \"whatev\", \"need\", \"hear\", \"somewher\", \"tonight\", \"enough\", \"level\", \"wow\", \"come\", \"defens\", \"back\", \"got\", \"didnt\", \"call\", \"high\", \"lose\", \"realli\", \"game\", \"see\", \"tripl\", \"tho\", \"rip\", \"leader\", \"doubl\", \"instinct\", \"closer\", \"combin\", \"individu\", \"garbag\", \"stone\", \"killer\", \"vision\", \"gon\", \"sleep\", \"flat\", \"circl\", \"open\", \"chicken\", \"credibl\", \"wide\", \"expos\", \"salad\", \"kyle\", \"aliv\", \"precious\", \"bathroom\", \"assassin\", \"martin\", \"mo\", \"nobodi\", \"respect\", \"west\", \"earth\", \"kat\", \"lanc\", \"anyon\", \"super\", \"wall\", \"behind\", \"legit\", \"surpris\", \"know\", \"easili\", \"hold\", \"els\", \"first\", \"even\", \"love\", \"part\", \"averag\", \"one\", \"lue\", \"team\", \"realli\", \"talk\", \"fan\"], \"Total\": [34.0, 33.0, 46.0, 22.0, 20.0, 18.0, 65.0, 16.0, 24.0, 42.0, 20.0, 26.0, 14.0, 65.0, 15.0, 54.0, 18.0, 15.0, 43.0, 15.0, 25.0, 27.0, 14.0, 16.0, 28.0, 24.0, 23.0, 17.0, 15.0, 11.0, 7.450448325470718, 12.243117872419631, 9.451684248794178, 5.12420473511686, 12.45090952645908, 4.734387355865978, 15.421643195151598, 4.661692047010079, 19.429193455813586, 5.307475919788008, 3.98674768573504, 10.531733416156454, 3.9120242455001355, 6.340119858219879, 5.405121793904927, 7.056321245500708, 4.927342318623335, 3.690376090660599, 3.665485607467455, 5.580314490031179, 3.6486593951261197, 9.610510503127346, 3.2184934182126956, 4.124752705086761, 17.486048201713402, 5.271955694357815, 3.005680967157448, 2.987340146385671, 8.112324809870724, 5.36623626665625, 4.473407761809453, 50.05717204500134, 14.131817012730421, 7.532794030506083, 54.094001014688374, 27.1459173610761, 26.446616418100838, 9.298090680082762, 17.39709984427068, 44.31902791756497, 50.83938110775041, 55.666029825659535, 31.64899323072309, 30.748718582740914, 43.43938370445096, 31.907263407381425, 22.557229390313427, 42.534115242505884, 17.085334982913253, 73.07671514440501, 73.07802639473098, 22.042278506809716, 14.0116817008664, 63.75446821792745, 103.7566885340031, 58.311188521147955, 39.477690418928795, 86.17286476194747, 62.83573788844407, 46.199652028368675, 47.35749621788397, 45.646765670016926, 60.79206113452543, 57.922332274182175, 27.55643744665297, 41.41814221277102, 78.83913077418624, 6.534829793136575, 7.721249129922045, 5.414702788605711, 15.936520449972148, 6.271818506477222, 4.740672824415675, 8.846764328795535, 4.048669868140183, 4.969162591681397, 3.9074705410192467, 3.570183454164814, 14.345620448290179, 8.460402429702333, 3.347071391630046, 5.1702105021545535, 5.867438301627821, 3.089055690926074, 6.90403084040545, 3.059624914960551, 4.511557803899903, 2.9812890170453574, 2.9626977448409657, 2.8852101800757017, 4.814759029902872, 2.855719230106989, 3.788161801118539, 4.04598224418967, 2.7353128955581427, 14.491631226014286, 3.7571073393002425, 6.28487153989666, 12.199233730674182, 17.597874880114325, 9.828687134114011, 27.921632043935645, 14.61986774024021, 5.1452982189134815, 6.686688177847774, 28.150576299713368, 5.971186204277442, 29.7998851371668, 10.334993073459469, 15.614954856551472, 36.52399095862181, 17.31235094582743, 20.429810651814968, 17.535181428913386, 17.58474530134544, 27.346407730988375, 60.79206113452543, 58.311188521147955, 36.292300522859726, 16.18101983113127, 20.18009051786107, 65.13663089300374, 29.822127211668594, 15.12916790605017, 32.67806011340817, 103.7566885340031, 55.93535597394874, 28.37425650007031, 40.547984860516735, 39.66049650095693, 45.52692116849513, 78.83913077418624, 86.17286476194747, 45.646765670016926, 8.120974881751152, 7.813319070140733, 6.0549308980943115, 5.615047149422455, 11.678227305818943, 5.355161111905687, 4.8074837393842005, 4.511846896429963, 8.799128781473623, 5.325562301788296, 3.774779235454879, 3.6906689846218175, 3.665917772618913, 3.4444902640987736, 3.442801043523194, 3.3858102358506024, 3.2238127834981727, 3.1325947336425286, 5.899422804526507, 3.094521239680865, 3.09153614502546, 5.823183050269454, 5.2314983090414815, 2.950993057596659, 2.830333804748634, 4.097688432855104, 2.832037651639378, 2.7505673631754113, 2.678270360032543, 2.6557433585439587, 8.22148653439298, 5.140130018221147, 12.79553204931571, 6.4427383164867, 7.216854233830797, 65.66437013626425, 25.533263279279552, 10.230625814815218, 13.49072960022319, 6.174941586580004, 23.271354141771354, 27.34237177425116, 28.959320409172495, 43.369787872362096, 16.384242026583696, 18.000672856410635, 13.153238026737132, 34.79435428059889, 16.25157725549807, 44.55387848514887, 30.236043964512696, 26.866250147839636, 31.131460896220556, 63.75446821792745, 78.83913077418624, 43.81827633243328, 52.39286432943649, 73.07802639473098, 44.271475216389796, 86.17286476194747, 36.52399095862181, 65.13663089300374, 10.26936717433488, 7.105809021132106, 33.386034403501334, 4.9434930522850875, 15.131296612202284, 4.61002093171586, 5.7102764790259055, 5.704010475479403, 5.013748334094497, 3.7767027674563227, 4.342884331687887, 6.323610605633225, 8.03780714552134, 3.544310090906535, 5.641356337540946, 7.670861123824881, 3.3268303503257863, 3.977182258502567, 5.098506423764504, 4.230146677393797, 3.020402070139777, 6.790723752503669, 3.404053490569124, 2.772070026043126, 6.074674573008643, 2.696499712413443, 3.323355337369588, 2.6845440389421094, 2.669150500812268, 5.301107446518378, 12.185443308653932, 9.017466018723962, 21.171847877258347, 4.347489715472271, 6.110688210053133, 43.8905002568467, 17.96785634611377, 22.300580224171526, 14.362614697958401, 54.17538700245401, 103.7566885340031, 12.289008024017253, 8.971071900557915, 32.751285322000115, 22.056554050085374, 53.41014471878121, 33.87158352933119, 41.11916035269511, 32.94367110767792, 65.13663089300374, 22.638396708502288, 39.18160051331334, 73.07802639473098, 55.93535597394874, 55.666029825659535, 32.068648895796244, 16.654802759622886, 78.83913077418624, 15.457166032231134, 5.881907312850373, 5.848335468665332, 7.727017506883187, 5.437736746600116, 11.333168517175029, 4.773149430512615, 10.917111493576442, 3.5708184564181287, 3.5157801536476496, 11.770895621940438, 3.3634879114414677, 7.323674947228964, 8.154419153481639, 5.92737621139783, 3.1691303199064254, 4.503197853176362, 3.046073904543636, 3.0173991061795067, 4.046390121324865, 8.057922388480195, 2.8662669349546017, 4.862271223846046, 4.492866407092928, 5.393186754373505, 3.207860312451114, 10.368149511557169, 3.9008419904353926, 12.552529887453264, 4.20199002663792, 6.942616014359642, 6.886309304918108, 8.716609223192473, 17.854289005569328, 21.485305954902188, 12.796405857814468, 57.24850187478383, 27.79755160132012, 21.86362697382326, 13.531929894312935, 10.561054682777199, 16.286414970305614, 9.721956670029629, 10.393403334102828, 52.39286432943649, 16.745153439159978, 24.91990920443373, 17.68343746842662, 46.199652028368675, 15.967118882509128, 86.17286476194747, 78.83913077418624, 13.179626833809746, 14.136784647668943, 73.07671514440501, 20.138545980961215, 63.75446821792745, 39.66049650095693, 103.7566885340031, 18.164276855848602, 7.709628244956742, 8.929293601455674, 5.2538487279419845, 5.132193006211112, 6.376601341986771, 4.566160794166793, 4.192612648268906, 3.9518465243422085, 3.7322003693391843, 6.245989067036231, 3.4247756637172335, 3.0970157558937133, 3.55782255569528, 3.7754059309750607, 6.320827227771128, 2.882289634720142, 5.235262689459775, 9.306225032879084, 2.6137141340735615, 2.6124754959477006, 6.867095369666566, 7.129208895396701, 2.545351931802314, 7.647830347318464, 2.4599819672636034, 2.4524765272869495, 2.4250442893882127, 6.087700014461296, 2.5839504981793273, 10.318299909093925, 14.34062078327144, 4.914895676118416, 8.009940816826864, 15.362965654747672, 13.027722118814527, 6.016420259426249, 16.066403486355817, 13.313180987096215, 11.156730428644423, 18.863843204522663, 22.876464786505828, 25.89226205384964, 18.193517853511196, 22.432287141798234, 15.868342433477794, 40.37530664801536, 11.77051561503364, 27.55643744665297, 73.07671514440501, 38.42258981237161, 23.6660386818995, 35.227794513553675, 78.83913077418624, 41.11916035269511, 11.327090550042643, 17.81952089270907, 62.83573788844407, 58.311188521147955, 55.666029825659535, 25.998908822832163, 20.208174662624273, 11.208868982337673, 8.272327028627933, 4.431402353224167, 6.243219243331764, 4.077768976005878, 15.559399869795024, 3.2910446823238537, 7.492929739826073, 4.689782628193714, 3.0977421838712966, 14.636786242167732, 2.983160262711612, 2.848150138672247, 2.841094272683686, 3.350075774302828, 2.683771604495145, 3.4506015853295584, 5.863378139256398, 4.36957329826358, 2.575372159502779, 3.2194745370394817, 24.09392156586103, 4.957213937140132, 8.848702748978225, 2.40742164936663, 6.227495072442377, 7.167692813131963, 2.744339084220614, 2.2760074497191827, 7.927285933310094, 6.5911402418941565, 13.709191645669094, 10.331755613181352, 14.282874785917116, 7.972750117557422, 6.679394622863226, 7.247825127055806, 12.225248677260925, 18.262457319629707, 10.07680047476684, 45.52692116849513, 34.898992642276184, 31.168078089369878, 86.17286476194747, 10.735947379003592, 32.57007274547215, 29.14480787608708, 27.06011876052188, 54.17538700245401, 24.79478544195675, 78.83913077418624, 17.77612901678811, 21.871374991050242, 103.7566885340031, 62.83573788844407, 53.41014471878121, 65.18954898493666, 26.27450747866193, 6.176600843377049, 6.020205474097135, 7.089117878587199, 5.486178932679933, 11.373130797996687, 7.869366913999239, 34.00301481507573, 5.280379604616949, 5.263874823813416, 4.102030308722118, 3.5503961026759856, 3.5105330539583632, 3.481273501648157, 7.151262555892787, 3.2616924969979078, 3.7528995766479714, 3.084569833478656, 6.838545629909592, 3.019351083714982, 5.487844693700255, 2.9413349777288023, 3.969582888273754, 2.866785722389058, 2.84141339471906, 5.28017450904971, 7.58240163884756, 4.1155675291235605, 3.357010747787443, 2.616175275583205, 2.597188117589604, 3.239667664101772, 5.004877129175021, 7.280958653060537, 46.918799993563525, 13.574277250984338, 26.27450747866193, 16.325601189488122, 5.987226675144839, 8.38846873916041, 11.144118353143496, 65.18954898493666, 11.60267092756532, 16.127109579186136, 33.36105047771809, 21.157072830739093, 18.951155819571742, 8.86695143243349, 11.859803822919366, 57.922332274182175, 23.20695305960356, 40.45389390587518, 65.13663089300374, 24.600335706068932, 39.574936980289394, 20.830604839173947, 65.66437013626425, 26.65388389460307, 52.39286432943649, 63.75446821792745, 43.64168721750783, 78.83913077418624, 8.387860100483769, 8.211080305252176, 7.214440413323595, 5.035836460021307, 4.794232148263121, 4.556528217570984, 4.946947405923326, 3.7061247559790726, 3.435567673194639, 3.2419302381976656, 20.715790199583804, 2.9589511028198414, 7.633523229886636, 5.487465345322661, 3.1883361019571077, 2.8027875930330937, 8.934869860714318, 3.2294254309630355, 2.6477956309113906, 5.102971403958904, 2.49556158706557, 2.4894192331298677, 4.121848075237395, 2.4753308037234745, 2.4742223574286197, 3.279648179941617, 4.456028899021934, 5.673857711978509, 8.230611132763377, 2.3262416022481807, 8.97144093806916, 18.543747470421955, 4.377064624799916, 10.21344800575944, 7.067193348928378, 42.576516466696546, 20.042069909687235, 24.58798858087706, 12.969965832776714, 10.852681467907525, 44.271475216389796, 10.185111598218976, 8.017995873621574, 16.886981798369764, 15.22650580868557, 12.404872535964838, 15.906687964979907, 39.477690418928795, 25.138952086891315, 50.83938110775041, 53.41014471878121, 41.41814221277102, 28.150576299713368, 19.83596232362564, 19.220289171874747, 55.93535597394874, 103.7566885340031, 58.311188521147955, 16.395717225058107, 14.44322434283521, 7.091047983045436, 6.830857524797814, 22.0338359744513, 4.696793769440081, 4.766130410659108, 5.5291391163535, 4.341814143794402, 4.033261850112156, 5.245443250693871, 3.792565237015719, 5.678577239020949, 3.4066756948522197, 3.695436440689506, 7.072985648306506, 5.253223837180955, 10.97993588737839, 3.065293264447976, 3.063832120459385, 7.063760398273226, 2.9731294705150266, 2.971462948359401, 6.0984787329129, 2.872343531345663, 2.753003454278313, 2.6570876677711324, 2.6011649296553943, 2.536829880359206, 3.221734308189169, 9.640802041849263, 16.101309874818853, 8.584731862650735, 5.281132120143669, 6.067462405101113, 17.53020152907141, 23.768681672508404, 12.347907045209872, 6.325863348805287, 12.764354826119977, 8.57284909171451, 8.655914505550506, 47.35749621788397, 9.482974305746286, 9.409466083411438, 17.27931238701899, 41.065774032317165, 62.83573788844407, 65.18954898493666, 17.491671209465455, 14.012752883044314, 86.17286476194747, 23.271354141771354, 73.07671514440501, 55.93535597394874, 26.65388389460307, 23.097494613068264], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.6117, 1.5968, 1.5953, 1.5579, 1.5574, 1.5432, 1.5421, 1.5401, 1.5071, 1.5069, 1.5061, 1.5027, 1.5015, 1.501, 1.4996, 1.4982, 1.4867, 1.4867, 1.4849, 1.484, 1.4636, 1.4545, 1.4472, 1.4403, 1.4338, 1.4251, 1.4247, 1.4226, 1.4201, 1.4175, 1.4063, 1.275, 1.3429, 1.3773, 1.1994, 1.2348, 1.2046, 1.3433, 1.2384, 1.083, 1.056, 1.019, 1.0432, 1.0112, 0.9047, 0.9716, 1.066, 0.855, 1.1437, 0.6712, 0.627, 1.0395, 1.2032, 0.5638, 0.2561, 0.45, 0.6614, 0.1927, 0.3523, 0.5325, 0.5016, 0.5134, 0.2516, 0.2279, 0.8598, 0.481, -0.1338, 1.9093, 1.892, 1.8794, 1.8773, 1.8659, 1.8573, 1.8404, 1.8235, 1.8235, 1.815, 1.7914, 1.789, 1.7783, 1.7729, 1.7577, 1.7554, 1.7476, 1.7458, 1.7443, 1.7423, 1.7355, 1.7333, 1.7238, 1.7228, 1.72, 1.7161, 1.7159, 1.702, 1.7013, 1.6946, 1.6939, 1.6854, 1.6689, 1.6786, 1.6017, 1.6151, 1.6887, 1.665, 1.4689, 1.6533, 1.3692, 1.5544, 1.4615, 1.2786, 1.4253, 1.3817, 1.4072, 1.3892, 1.2406, 0.9712, 0.9771, 1.1119, 1.3911, 1.3067, 0.8333, 1.1116, 1.3976, 1.0142, 0.3489, 0.6079, 0.9951, 0.7419, 0.7285, 0.6147, 0.1894, -0.0497, 0.442, 2.2142, 2.2101, 2.1779, 2.1664, 2.161, 2.1587, 2.1394, 2.1268, 2.1009, 2.0901, 2.0858, 2.08, 2.0781, 2.061, 2.0608, 2.056, 2.0411, 2.0319, 2.0315, 2.0279, 2.0275, 2.0222, 2.0146, 2.0116, 1.9965, 1.9866, 1.9865, 1.9856, 1.9751, 1.9717, 1.9638, 1.9666, 1.9234, 1.9111, 1.8957, 1.5774, 1.6551, 1.7579, 1.6705, 1.8544, 1.4675, 1.4065, 1.3757, 1.2192, 1.5298, 1.4894, 1.5939, 1.182, 1.4178, 0.9038, 1.0844, 1.133, 1.0386, 0.4736, 0.1696, 0.5393, 0.3441, 0.0657, 0.4372, -0.1661, 0.5815, 0.001, 2.2785, 2.2465, 2.1942, 2.1919, 2.1898, 2.1785, 2.1749, 2.1555, 2.1554, 2.1331, 2.1307, 2.1212, 2.1202, 2.1164, 2.1014, 2.1001, 2.0981, 2.0979, 2.0937, 2.0909, 2.067, 2.062, 2.045, 2.036, 2.0316, 2.0251, 2.0246, 2.0234, 2.021, 2.0074, 1.9719, 1.9535, 1.827, 1.9794, 1.926, 1.5426, 1.6982, 1.615, 1.7122, 1.2827, 0.9416, 1.6677, 1.7765, 1.2081, 1.3732, 0.9411, 1.1329, 0.9763, 1.0459, 0.5224, 1.1681, 0.7028, 0.1784, 0.3451, 0.2478, 0.6888, 1.2675, -0.1858, 2.2545, 2.2497, 2.2488, 2.1988, 2.1954, 2.1893, 2.1765, 2.1586, 2.1474, 2.1431, 2.1398, 2.1304, 2.1264, 2.1233, 2.1188, 2.107, 2.1039, 2.099, 2.0958, 2.0924, 2.0808, 2.0777, 2.0258, 2.0252, 2.0202, 1.9996, 1.9967, 1.9966, 1.9859, 1.9855, 1.9756, 1.9469, 1.8957, 1.767, 1.7354, 1.7852, 1.395, 1.5578, 1.5889, 1.7268, 1.7824, 1.6272, 1.8006, 1.7655, 1.073, 1.5504, 1.3211, 1.4868, 0.8698, 1.4824, 0.3575, 0.2273, 1.5481, 1.4852, 0.0337, 1.1722, 0.0915, 0.5267, -0.4751, 2.4219, 2.3742, 2.3417, 2.3212, 2.3171, 2.3005, 2.2946, 2.277, 2.2632, 2.2489, 2.2318, 2.2254, 2.1944, 2.1913, 2.1857, 2.1785, 2.1696, 2.1525, 2.1436, 2.1316, 2.1314, 2.1312, 2.1308, 2.1204, 2.1203, 2.1053, 2.1039, 2.0987, 2.0883, 2.0881, 2.0811, 1.999, 2.0606, 2.0211, 1.9139, 1.9057, 2.0131, 1.8526, 1.8641, 1.8977, 1.7696, 1.6796, 1.6004, 1.6637, 1.5855, 1.6926, 1.1853, 1.734, 1.2741, 0.5972, 0.9411, 1.2404, 0.9492, 0.1628, 0.6242, 1.724, 1.3068, 0.1528, 0.186, 0.2296, 0.9392, 2.4249, 2.3674, 2.3149, 2.2897, 2.2785, 2.2713, 2.2287, 2.2142, 2.212, 2.2009, 2.195, 2.1847, 2.1823, 2.1657, 2.1648, 2.1432, 2.1428, 2.1426, 2.1328, 2.1288, 2.1258, 2.1171, 2.11, 2.1055, 2.1044, 2.0956, 2.0906, 2.0756, 2.0691, 2.0682, 2.0598, 2.0283, 1.9496, 1.974, 1.9176, 1.9931, 1.9981, 1.9052, 1.7491, 1.6283, 1.7874, 1.2537, 1.3082, 1.308, 0.8068, 1.7275, 1.1783, 1.2111, 1.2027, 0.8047, 1.2509, 0.4857, 1.409, 1.2158, 0.0766, 0.2713, 0.292, 0.027, 0.8825, 2.354, 2.3503, 2.3491, 2.336, 2.3107, 2.3011, 2.2943, 2.2705, 2.2547, 2.2501, 2.2429, 2.2398, 2.2375, 2.2314, 2.2181, 2.2151, 2.2004, 2.1994, 2.1931, 2.1852, 2.1841, 2.1796, 2.1748, 2.1715, 2.1685, 2.1614, 2.1597, 2.1479, 2.1391, 2.1361, 2.1327, 2.1014, 2.0616, 1.8581, 1.945, 1.8439, 1.9075, 2.0638, 1.9874, 1.919, 1.4335, 1.8541, 1.7422, 1.4089, 1.5693, 1.5899, 1.8699, 1.7438, 0.9863, 1.3959, 1.0923, 0.5125, 1.1683, 0.7893, 1.2628, 0.3827, 1.01, 0.3419, 0.0942, 0.4451, -0.1654, 2.4282, 2.426, 2.4117, 2.3589, 2.3399, 2.3398, 2.3188, 2.2923, 2.2716, 2.2543, 2.2425, 2.2242, 2.2135, 2.2064, 2.2056, 2.2046, 2.1895, 2.1848, 2.1823, 2.1615, 2.1571, 2.156, 2.1536, 2.1535, 2.1533, 2.1519, 2.1498, 2.1484, 2.1358, 2.1242, 2.1059, 2.0828, 2.1097, 2.0222, 2.0225, 1.7416, 1.8586, 1.8067, 1.8627, 1.8843, 1.4777, 1.8873, 1.9536, 1.6866, 1.6205, 1.7063, 1.5587, 1.0658, 1.2316, 0.5686, 0.4555, 0.6513, 0.9306, 1.192, 1.2049, 0.2514, -0.3282, 0.159, 2.5137, 2.5107, 2.4806, 2.4759, 2.4355, 2.417, 2.4097, 2.3941, 2.3941, 2.3842, 2.3718, 2.3695, 2.364, 2.3405, 2.3193, 2.3192, 2.3168, 2.3136, 2.3077, 2.3075, 2.3064, 2.2973, 2.2971, 2.294, 2.2851, 2.2692, 2.2552, 2.2465, 2.2359, 2.2308, 2.1787, 2.1284, 2.1653, 2.1925, 2.1705, 1.9932, 1.9031, 1.9566, 2.0783, 1.839, 1.9396, 1.9311, 1.1247, 1.8854, 1.8454, 1.4251, 0.8151, 0.5142, 0.4004, 1.2965, 1.4822, -0.0925, 1.0165, -0.0617, 0.1743, 0.868, 1.0046], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.9848, -5.5029, -5.7633, -6.4128, -5.5255, -6.5067, -5.3268, -6.5252, -5.1309, -6.4287, -6.7157, -5.7476, -6.7392, -6.2568, -6.4178, -6.1526, -6.5232, -6.8123, -6.8209, -6.4014, -6.8468, -5.8873, -6.9886, -6.7474, -5.3095, -6.5172, -7.0795, -7.0878, -6.0912, -6.5071, -6.7003, -4.4166, -5.6134, -6.2081, -4.4146, -5.0687, -5.125, -6.0316, -5.51, -4.7303, -4.62, -4.5664, -5.1068, -5.1677, -4.9286, -5.1703, -5.4227, -4.9994, -5.6228, -4.642, -4.6862, -5.4723, -5.7616, -4.8858, -4.7066, -5.0889, -5.2676, -4.9557, -5.1119, -5.2392, -5.2454, -5.2704, -5.2457, -5.3177, -5.4287, -5.4, -5.3711, -5.8183, -5.6687, -6.0362, -4.9588, -5.9027, -6.1912, -5.5843, -6.3828, -6.178, -6.4269, -6.5407, -5.1523, -5.691, -6.6237, -6.2041, -6.0799, -6.7293, -5.9268, -6.7421, -6.3558, -6.7769, -6.7853, -6.8213, -6.3103, -6.8354, -6.5567, -6.4911, -6.8964, -5.2298, -6.5865, -6.0727, -5.4179, -5.068, -5.6408, -4.6736, -5.3073, -6.2779, -6.0396, -4.7983, -6.1645, -4.841, -5.7148, -5.3949, -4.7282, -5.328, -5.206, -5.3333, -5.3485, -5.0555, -4.526, -4.5618, -4.9012, -5.4298, -5.2934, -4.5949, -5.0978, -5.4905, -5.1038, -4.6138, -4.9727, -5.2642, -5.1603, -5.1959, -5.1717, -5.0479, -5.198, -5.3418, -5.296, -5.3388, -5.626, -5.7129, -4.986, -5.768, -5.8952, -5.9712, -5.3292, -5.8421, -6.1905, -6.2189, -6.2275, -6.307, -6.3076, -6.3291, -6.3931, -6.4309, -5.7983, -6.4472, -6.4485, -5.8206, -5.9354, -6.5109, -6.5678, -6.2076, -6.5772, -6.6073, -6.6444, -6.6563, -5.5342, -6.0011, -5.1322, -5.8307, -5.7326, -3.8428, -4.7096, -5.5214, -5.3322, -5.9298, -4.99, -4.8897, -4.8631, -4.6158, -5.2786, -5.2249, -5.4341, -4.8732, -5.3987, -4.9042, -5.1112, -5.1809, -5.1279, -4.9761, -5.0677, -5.2854, -5.3019, -5.2475, -5.3772, -5.3144, -5.4253, -5.4272, -4.997, -5.3973, -3.9024, -5.8147, -4.6981, -5.898, -5.6875, -5.7081, -5.8371, -6.1427, -6.0055, -5.6392, -5.4004, -6.223, -5.7731, -5.4672, -6.3046, -6.1262, -5.8821, -6.0716, -6.4323, -5.6271, -6.3347, -6.5492, -5.769, -6.5876, -6.3792, -6.5938, -6.6019, -5.9294, -5.1326, -5.4521, -4.725, -6.1557, -5.8686, -4.2804, -5.0179, -4.8851, -5.2279, -4.3297, -4.021, -5.4283, -5.6342, -4.9076, -5.1379, -4.6856, -4.9493, -4.9119, -5.064, -4.9058, -5.317, -5.2337, -5.1348, -5.2354, -5.3375, -5.4481, -5.5246, -5.4231, -4.6122, -5.5831, -5.5897, -5.3612, -5.716, -4.9877, -5.8652, -5.0557, -6.1845, -6.2044, -4.9993, -6.2614, -5.4872, -5.3829, -5.7064, -6.3442, -5.996, -6.3918, -6.4045, -6.1145, -5.4373, -6.474, -5.9974, -6.077, -5.8994, -6.4395, -5.2693, -6.2469, -5.0889, -6.1837, -5.6914, -5.7283, -5.5438, -4.9555, -4.8019, -5.2703, -4.1624, -4.722, -4.931, -5.2729, -5.4652, -5.1872, -5.5297, -5.498, -4.5729, -5.2362, -5.0679, -5.2453, -4.9019, -5.3518, -4.7909, -5.01, -5.4779, -5.4707, -5.2795, -5.4299, -5.3582, -5.3977, -5.4378, -4.2833, -5.188, -5.0737, -5.6246, -5.652, -5.4516, -5.7914, -5.8944, -5.9673, -6.0388, -5.5409, -6.1482, -6.2799, -6.1442, -6.0905, -5.5823, -6.3766, -5.7968, -5.2304, -6.5124, -6.513, -5.5467, -5.5097, -6.5501, -5.45, -6.5993, -6.6037, -6.6202, -5.7102, -6.5673, -5.1897, -4.9426, -5.9518, -5.5029, -4.9588, -5.132, -5.7971, -4.9754, -5.1518, -5.2949, -4.8979, -4.795, -4.7504, -5.0399, -4.9087, -5.1478, -4.7211, -5.4051, -5.0144, -4.716, -5.015, -5.2002, -5.0936, -5.0745, -5.264, -5.4535, -5.4176, -5.3114, -5.3529, -5.3557, -5.4075, -4.1738, -4.8206, -5.1769, -5.8263, -5.4948, -5.9278, -4.6314, -6.1993, -5.3787, -5.8585, -6.279, -4.7365, -6.3295, -6.3923, -6.3957, -6.2525, -6.4747, -6.2235, -5.7031, -6.0012, -6.533, -6.3184, -4.3128, -5.8984, -5.32, -6.6305, -5.6851, -5.5595, -6.5261, -6.7141, -5.4746, -5.6907, -5.0371, -5.2955, -5.028, -5.5356, -5.7076, -5.7188, -5.3521, -5.0715, -5.5071, -4.5327, -4.744, -4.8574, -4.3416, -5.5037, -4.943, -5.0214, -5.1039, -4.8078, -5.1432, -4.7516, -5.3179, -5.3037, -4.8861, -5.1929, -5.3348, -5.4005, -5.4536, -5.4299, -5.4593, -5.297, -5.5665, -4.8627, -5.2407, -3.7839, -5.6702, -5.6891, -5.9432, -6.0947, -6.1091, -6.1199, -5.406, -6.2043, -6.0671, -6.278, -5.4828, -6.3066, -5.717, -6.3418, -6.0464, -6.3767, -6.3889, -5.7723, -5.4175, -6.0302, -6.2458, -6.5039, -6.5142, -6.2966, -5.8929, -5.5579, -3.8982, -5.0515, -4.4922, -4.9045, -5.7513, -5.4905, -5.2748, -3.9939, -5.2994, -5.082, -4.6885, -4.9834, -5.0729, -5.5525, -5.3878, -4.5593, -5.0643, -4.8123, -4.9157, -5.2337, -5.1373, -5.3055, -5.0375, -5.3118, -5.3041, -5.3555, -5.3836, -5.4027, -5.0497, -5.0732, -5.2169, -5.6292, -5.6974, -5.7483, -5.6872, -6.0024, -6.0989, -6.1743, -4.3313, -6.2957, -5.3586, -5.6959, -6.2396, -6.3695, -5.2252, -6.2476, -6.4487, -5.8134, -6.5331, -6.5367, -6.0348, -6.5449, -6.5455, -6.2651, -5.9606, -5.7204, -5.361, -6.6363, -5.3048, -4.6018, -6.0186, -5.2588, -5.6268, -4.1119, -4.7483, -4.5957, -5.1794, -5.336, -4.3366, -5.3965, -5.5695, -5.0916, -5.2612, -5.3803, -5.2792, -4.8631, -5.1487, -5.1074, -5.1713, -5.2297, -5.3365, -5.4252, -5.4439, -5.3291, -5.2908, -5.3799, -4.294, -4.4238, -5.1653, -5.2073, -4.0767, -5.6409, -5.6335, -5.5006, -5.7424, -5.826, -5.5756, -5.9022, -5.504, -6.0385, -5.9783, -5.3293, -5.629, -4.895, -6.1769, -6.1775, -5.3433, -6.2178, -6.2185, -5.5026, -6.2645, -6.3228, -6.3722, -6.4022, -6.4379, -6.204, -5.16, -4.6974, -5.2894, -5.7481, -5.6313, -4.7475, -4.5332, -5.1346, -5.6817, -5.2191, -5.5165, -5.5154, -4.6223, -5.4698, -5.5176, -5.3301, -5.0744, -4.95, -5.0271, -5.4465, -5.4825, -5.2409, -5.441, -5.3749, -5.4062, -5.4538, -5.4604]}, \"token.table\": {\"Topic\": [1, 2, 4, 5, 9, 10, 2, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 5, 7, 8, 8, 1, 10, 1, 3, 4, 5, 8, 1, 2, 3, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 6, 9, 2, 6, 8, 7, 1, 3, 4, 5, 6, 7, 9, 10, 3, 6, 7, 8, 8, 6, 6, 2, 10, 2, 8, 9, 1, 3, 7, 8, 10, 5, 1, 3, 8, 9, 10, 1, 5, 6, 8, 10, 2, 4, 8, 1, 2, 3, 4, 5, 7, 8, 9, 10, 7, 1, 2, 3, 4, 5, 6, 7, 9, 1, 2, 3, 6, 8, 10, 3, 1, 2, 3, 4, 5, 6, 8, 9, 10, 10, 8, 1, 6, 7, 9, 6, 2, 5, 6, 9, 10, 1, 2, 3, 4, 6, 2, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 5, 8, 10, 2, 6, 8, 3, 10, 2, 5, 9, 7, 3, 6, 8, 8, 2, 4, 5, 9, 2, 4, 9, 7, 9, 10, 9, 8, 1, 5, 6, 7, 10, 3, 4, 5, 4, 7, 9, 1, 2, 9, 8, 2, 3, 5, 6, 9, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 6, 10, 4, 10, 1, 9, 1, 3, 4, 5, 8, 3, 4, 6, 10, 2, 4, 7, 10, 5, 9, 2, 5, 10, 6, 7, 1, 3, 5, 9, 9, 10, 1, 2, 3, 5, 7, 8, 9, 10, 3, 5, 1, 8, 3, 4, 8, 2, 8, 1, 5, 1, 2, 3, 4, 5, 6, 7, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 3, 5, 2, 4, 1, 2, 3, 4, 5, 6, 7, 10, 10, 7, 1, 2, 3, 4, 9, 10, 9, 8, 1, 2, 3, 6, 8, 9, 10, 1, 5, 3, 5, 1, 2, 3, 4, 5, 8, 1, 5, 6, 7, 4, 5, 6, 8, 2, 1, 2, 3, 6, 7, 9, 10, 6, 1, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 2, 4, 8, 4, 1, 1, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 10, 1, 8, 9, 1, 5, 7, 6, 7, 8, 2, 3, 6, 2, 8, 1, 2, 4, 5, 6, 7, 8, 9, 10, 2, 4, 7, 5, 2, 3, 6, 7, 9, 6, 1, 2, 3, 4, 7, 3, 2, 3, 6, 9, 10, 1, 6, 10, 5, 1, 3, 4, 5, 6, 7, 8, 9, 1, 8, 3, 1, 4, 2, 2, 1, 2, 4, 6, 7, 9, 10, 1, 8, 1, 2, 3, 4, 6, 7, 9, 10, 1, 3, 4, 8, 9, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 6, 7, 8, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 5, 6, 8, 9, 1, 2, 3, 5, 3, 5, 10, 2, 3, 4, 5, 9, 10, 4, 5, 1, 2, 3, 5, 1, 2, 4, 6, 7, 8, 10, 4, 5, 1, 2, 3, 4, 5, 6, 7, 9, 5, 8, 1, 2, 3, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 9, 1, 4, 5, 9, 1, 10, 8, 6, 3, 1, 2, 9, 4, 6, 2, 7, 8, 9, 4, 1, 5, 1, 2, 4, 6, 2, 3, 4, 5, 8, 9, 1, 5, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 2, 3, 4, 5, 6, 8, 10, 9, 1, 2, 4, 5, 6, 8, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 7, 8, 10, 1, 2, 7, 8, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 1, 2, 3, 4, 5, 6, 7, 8, 10, 4, 2, 4, 6, 9, 2, 3, 5, 6, 8, 10, 1, 2, 3, 4, 5, 6, 7, 10, 6, 8, 9, 9, 8, 1, 2, 8, 1, 2, 3, 1, 2, 3, 4, 6, 7, 8, 9, 10, 5, 1, 2, 3, 4, 10, 1, 2, 3, 4, 6, 9, 4, 1, 5, 6, 9, 1, 2, 3, 4, 5, 6, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 2, 3, 4, 5, 6, 10, 2, 3, 7, 9, 1, 2, 3, 5, 7, 9, 7, 3, 1, 2, 1, 6, 8, 9, 10, 1, 2, 5, 3, 6, 7, 2, 9, 6, 1, 2, 4, 5, 6, 8, 10, 4, 1, 2, 4, 5, 6, 8, 10, 2, 2, 4, 5, 8, 2, 10, 6, 8, 1, 2, 4, 5, 6, 9, 10, 2, 10, 1, 6, 10, 3, 8, 2, 4, 5, 7, 3, 7, 3, 5, 1, 2, 3, 4, 5, 7, 10, 4, 9, 2, 5, 10, 1, 2, 4, 5, 9, 2, 10, 7, 1, 3, 9, 1, 2, 3, 4, 5, 7, 8, 9, 10, 1, 10, 1, 3, 6, 9, 10, 3, 4, 5, 10, 1, 2, 3, 4, 5, 7, 8, 9, 2, 5, 2, 4, 5, 9, 10, 1, 2, 3, 4, 5, 7, 10, 1, 5, 7, 10, 1, 2, 9, 4, 8, 2, 4, 10, 1, 2, 3, 5, 7, 9, 1, 2, 3, 4, 6, 9, 7, 1, 2, 3, 1, 2, 3, 3, 6, 1, 2, 6, 8, 10, 4, 5, 4, 1, 2, 7, 9, 4, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 7, 1, 2, 3, 5, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 8, 1, 3, 5, 7, 10, 8, 1, 3, 7, 8, 1, 2, 3, 4, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 4, 5, 6, 7, 8, 10, 4, 1, 3, 1, 4, 9, 1, 3, 5, 6, 7, 9, 10, 2, 9, 4, 4, 5, 7, 8, 6, 6, 10, 3, 5, 8, 6, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 7, 9, 10, 4, 9, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 6, 1, 2, 3, 5, 6, 8, 9, 10, 2, 3, 4, 5, 9, 1, 2, 4, 5, 6, 7, 9, 10, 2, 5, 6, 8, 10, 3, 8, 10, 1, 2, 3, 6, 7, 1, 7, 8, 4, 1, 2, 7, 8, 9, 1, 2, 3, 6, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 5, 10, 7, 7, 3, 2, 3, 5, 6, 1, 1, 4, 5, 6, 10, 3, 1, 2, 9, 10, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 4, 7, 1, 5, 6, 7, 9, 2, 5, 6, 8, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 4, 5, 6, 7, 8, 9, 10, 3, 5, 6, 7, 1, 2, 4, 5, 7, 8, 9, 10, 7, 3, 6, 10, 1, 2, 3, 4, 5, 6, 7, 10, 4, 10, 4, 1, 2, 8, 1, 3, 4, 5, 8, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 9, 1, 3, 4, 5, 9, 10, 4, 5, 1, 3, 6, 9, 1, 4, 2, 4, 5, 6, 1, 2, 4, 5, 7, 9, 10, 4, 5, 7, 2, 3, 6, 7, 8, 9, 2, 9, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 7, 3, 4, 2, 3, 9, 3, 4, 7, 3, 2, 3, 4, 6, 9, 5, 9, 7, 3, 9, 1, 4, 6, 10, 3, 4, 5, 1, 5, 3, 5, 6, 7, 8, 9, 1, 2, 3, 4, 5, 7, 8, 9, 10, 10, 2, 4, 8, 3, 2, 3, 4, 7, 1, 2, 3, 4, 5, 7, 8, 9, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 5, 7, 1, 2, 4, 7, 9, 9, 8, 1, 2, 3, 4, 5, 7, 8, 9, 10, 7, 1, 3, 4, 5, 10, 1, 2, 3, 4, 5, 6, 7, 9, 10, 1, 2, 3, 4, 6, 7, 9, 5, 1, 3, 4, 5, 7, 1, 2, 5, 9, 9, 6, 3, 3, 3, 1, 2, 3, 7, 8, 9, 10, 1, 2, 3, 4, 5, 8, 9, 1, 2, 3, 4, 6, 10, 2, 1, 3, 5, 1, 2, 5, 7, 1, 1, 2, 8, 10, 2, 6, 4, 6, 7, 1, 2, 3, 4, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 6, 7, 9, 3, 7, 1, 4, 5, 7, 8, 9, 10, 6, 9, 1, 2, 6, 1, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 10, 1, 2, 6, 7, 8, 9, 2, 6, 1, 4, 6, 2, 1, 1, 6, 9, 10, 4, 1, 2, 3, 5, 6, 8, 9, 1, 4, 5, 8, 10, 1, 1, 2, 3, 4, 5, 6, 7, 8, 1, 2, 3, 4, 5, 6, 8, 9, 10, 3, 8, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 3, 7, 8, 10, 2, 1, 5, 1, 5, 6, 7, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 5, 1, 2, 3, 4, 5, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 4, 10, 1, 2, 4, 5, 6, 7, 8, 9, 1, 4, 6, 7, 10, 9, 5, 7, 1, 5, 8, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 3, 9, 1, 2, 1, 1, 2, 7, 9, 10, 1, 6, 7, 9, 1, 2, 4, 5, 6, 7, 9, 10, 3, 6, 9, 1, 3, 4, 5, 2, 4, 1, 4, 9, 9, 1, 10, 1, 10, 5, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 2, 3, 3, 1, 9, 1, 8, 1, 2, 7, 3, 4, 6, 9, 10, 4, 1, 2, 3, 4, 5, 6, 7, 8, 9, 1, 2, 3, 5, 6, 8, 9, 10, 1, 10, 2, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 1, 2, 3, 4, 5, 7, 8, 9, 10, 2, 5, 6, 7, 5, 1, 2, 3, 4, 2, 4, 10, 8, 1, 2, 5, 6, 7, 10, 1, 2, 3, 7, 8, 9, 6, 7, 4, 10, 1, 2, 4, 5, 6, 7, 8, 9, 10, 1, 3, 7, 8, 9, 1, 3, 4, 6, 7, 8, 9, 10, 4, 1, 8, 1, 3, 4, 7, 8, 9, 10, 1, 7, 9, 10, 7, 1, 2, 1, 3, 5, 1, 2, 3, 4, 9, 10, 1, 3, 10, 2, 7, 1, 2, 5, 6, 9, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 7, 1, 2, 6, 9, 2, 3, 6, 8, 5], \"Freq\": [0.5852972745340274, 0.1755891823602082, 0.058529727453402736, 0.058529727453402736, 0.058529727453402736, 0.058529727453402736, 0.11921126859919472, 0.11921126859919472, 0.5960563429959737, 0.2586626533551836, 0.14370147408621312, 0.3161432429896689, 0.028740294817242627, 0.057480589634485255, 0.057480589634485255, 0.057480589634485255, 0.08622088445172787, 0.0892150672450312, 0.892150672450312, 0.6623939861737503, 0.7289395639290777, 0.9395407758307942, 0.6962955434035499, 0.11130988368752046, 0.05565494184376023, 0.500894476593842, 0.2226197673750409, 0.05565494184376023, 0.08025711424519001, 0.040128557122595006, 0.16051422849038002, 0.20064278561297502, 0.36115701410335505, 0.12038567136778502, 0.15128403649347233, 0.27735406690469927, 0.07564201824673616, 0.050428012164490776, 0.15128403649347233, 0.07564201824673616, 0.025214006082245388, 0.025214006082245388, 0.050428012164490776, 0.10085602432898155, 0.23151176814717322, 0.09921932920593139, 0.29765798761779416, 0.06614621947062092, 0.16536554867655232, 0.03307310973531046, 0.06614621947062092, 0.8432123730278986, 0.8525065813231038, 0.7409841003850716, 0.7793939150688795, 0.7700635877913065, 0.6051786422860602, 0.08414433865355107, 0.04207216932677554, 0.08414433865355107, 0.08414433865355107, 0.08414433865355107, 0.04207216932677554, 0.08414433865355107, 0.5048660319213065, 0.14971416669664211, 0.14971416669664211, 0.5988566667865685, 0.14971416669664211, 0.5957681253532391, 0.7155442803042333, 0.813014089784052, 0.653674896625617, 0.7688862698394764, 0.11192104816175272, 0.11192104816175272, 0.6715262889705162, 0.1635958541865916, 0.0817979270932958, 0.49078756255977474, 0.0817979270932958, 0.1635958541865916, 0.7356001561680887, 0.21409069474350428, 0.14272712982900287, 0.07136356491450144, 0.21409069474350428, 0.35681782457250716, 0.2985938598990124, 0.41803140385861737, 0.11943754395960496, 0.05971877197980248, 0.05971877197980248, 0.8402929537137191, 0.16702223821779866, 0.6680889528711946, 0.5114145655096561, 0.059009372943421866, 0.059009372943421866, 0.039339581962281246, 0.039339581962281246, 0.039339581962281246, 0.059009372943421866, 0.13768853686798435, 0.019669790981140623, 0.579609077009389, 0.13812478827137983, 0.06906239413568992, 0.37984316774629456, 0.10359359120353488, 0.06906239413568992, 0.06906239413568992, 0.03453119706784496, 0.13812478827137983, 0.1916548497651949, 0.4654474922869019, 0.1642755855130242, 0.0273792642521707, 0.0273792642521707, 0.0821377927565121, 0.8128607611520624, 0.2890966161209808, 0.06424369247132908, 0.2890966161209808, 0.12848738494265816, 0.06424369247132908, 0.03212184623566454, 0.03212184623566454, 0.06424369247132908, 0.06424369247132908, 0.7527038058468267, 0.6131785880615106, 0.2489667338055432, 0.5601751510624722, 0.1244833669027716, 0.1244833669027716, 0.8155021985929051, 0.23502950527989355, 0.0783431684266312, 0.0783431684266312, 0.1566863368532624, 0.4700590105597871, 0.21985852500911657, 0.21985852500911657, 0.05496463125227914, 0.05496463125227914, 0.43971705001823314, 0.7414763137698447, 0.6392690336408146, 0.11986294380765272, 0.019977157301275455, 0.019977157301275455, 0.019977157301275455, 0.03995431460255091, 0.05993147190382636, 0.019977157301275455, 0.03995431460255091, 0.22444735093788293, 0.13466841056272974, 0.2468920860316712, 0.06733420528136487, 0.06733420528136487, 0.04488947018757658, 0.06733420528136487, 0.06733420528136487, 0.08977894037515316, 0.02244473509378829, 0.14389756541759735, 0.21584634812639603, 0.14389756541759735, 0.43169269625279205, 0.03597439135439934, 0.03597439135439934, 0.13075603858689505, 0.6537801929344752, 0.13075603858689505, 0.7033705175613475, 0.23445683918711582, 0.690053441468256, 0.0690053441468256, 0.20701603244047678, 0.8307643160582946, 0.8959060723311683, 0.6457829593517374, 0.8095067378947312, 0.6799633551239822, 0.4944064146444281, 0.12360160366110702, 0.12360160366110702, 0.12360160366110702, 0.11089589890592207, 0.6653753934355324, 0.22179179781184413, 0.17624692947248652, 0.7049877178899461, 0.17624692947248652, 0.6759151910601112, 0.8463676444319118, 0.06509159900978927, 0.06509159900978927, 0.5858243910881034, 0.19527479702936779, 0.06509159900978927, 0.6469275810403081, 0.25635491067106386, 0.7690647320131916, 0.8765762302671379, 0.1310011078612845, 0.786006647167707, 0.14149888797815802, 0.14149888797815802, 0.5659955519126321, 0.7557469095461072, 0.5683720229970182, 0.07104650287462727, 0.1065697543119409, 0.035523251437313635, 0.2131395086238818, 0.23423720378947774, 0.15615813585965183, 0.05205271195321727, 0.026026355976608635, 0.05205271195321727, 0.20821084781286908, 0.13013177988304317, 0.07807906792982591, 0.07807906792982591, 0.09675865217249405, 0.5805519130349643, 0.09675865217249405, 0.09675865217249405, 0.6900533862848041, 0.23001779542826803, 0.7806089348045494, 0.7943069700049544, 0.08618705177824412, 0.08618705177824412, 0.17237410355648825, 0.08618705177824412, 0.5171223106694647, 0.6780324334324506, 0.15820714029429714, 0.7910357014714856, 0.6524661190485397, 0.17726233553895615, 0.7090493421558246, 0.7452198974943055, 0.7614371905664933, 0.6169956100529921, 0.20566520335099736, 0.7919408297486615, 0.6565828875710227, 0.8392552564349242, 0.22885529815860714, 0.6865658944758214, 0.23498758988903107, 0.5091397780929007, 0.07832919662967702, 0.15665839325935405, 0.6169164210985273, 0.9042999090421746, 0.3546306749821228, 0.05066152499744611, 0.1266538124936153, 0.05066152499744611, 0.07599228749616917, 0.025330762498723056, 0.22797686248850751, 0.10132304999489222, 0.8709561560583853, 0.8401435235689035, 0.8117966525040565, 0.8449761416025823, 0.0898579317250502, 0.8386740294338019, 0.05990528781670013, 0.7736628901924016, 0.1934157225481004, 0.08823657730709063, 0.7941291957638156, 0.1666604367475964, 0.05555347891586547, 0.44442783132692376, 0.05555347891586547, 0.05555347891586547, 0.11110695783173094, 0.05555347891586547, 0.05555347891586547, 0.8257732555748352, 0.22290852372863385, 0.09907045499050393, 0.049535227495251966, 0.07430284124287795, 0.049535227495251966, 0.2724437512238858, 0.07430284124287795, 0.049535227495251966, 0.09907045499050393, 0.12263289158652539, 0.7357973495191523, 0.7984866358805567, 0.6018014316768744, 0.08066212166594026, 0.16132424333188053, 0.04033106083297013, 0.08066212166594026, 0.08066212166594026, 0.20165530416485067, 0.28231742583079095, 0.08066212166594026, 0.6527772806625332, 0.7765867906198595, 0.27202798707247633, 0.1813519913816509, 0.13601399353623816, 0.3627039827633018, 0.045337997845412724, 0.045337997845412724, 0.8316653345586206, 0.7575212957232398, 0.14919392654885213, 0.08525367231362979, 0.08525367231362979, 0.042626836156814896, 0.5328354519601861, 0.08525367231362979, 0.021313418078407448, 0.7886286240342236, 0.1577257248068447, 0.832036095563033, 0.8532956751824986, 0.13422870529830158, 0.503357644868631, 0.13422870529830158, 0.1006715289737262, 0.06711435264915079, 0.06711435264915079, 0.09159932099149061, 0.8243938889234155, 0.09159932099149061, 0.7356964108688819, 0.13946397650602627, 0.13946397650602627, 0.6275878942771181, 0.06973198825301313, 0.9065890612016392, 0.27845233865774954, 0.19889452761267823, 0.03977890552253565, 0.03977890552253565, 0.0795578110450713, 0.27845233865774954, 0.0795578110450713, 0.7591387928455433, 0.20769471406343112, 0.8307788562537245, 0.2897281084785081, 0.14486405423925405, 0.07243202711962703, 0.024144009039875677, 0.07243202711962703, 0.024144009039875677, 0.07243202711962703, 0.04828801807975135, 0.14486405423925405, 0.0965760361595027, 0.7946165405385165, 0.08431842675740345, 0.42159213378701726, 0.5059105605444207, 0.8091444567017312, 0.6694918897735044, 0.8448822834582681, 0.662822493684738, 0.31370350281387954, 0.07842587570346989, 0.15685175140693977, 0.04705552542208193, 0.09411105084416387, 0.03137035028138796, 0.06274070056277592, 0.09411105084416387, 0.06274070056277592, 0.06274070056277592, 0.09076948754266131, 0.04538474377133066, 0.8623101316552825, 0.11146481450450486, 0.11146481450450486, 0.6687888870270292, 0.0849553026480027, 0.7645977238320244, 0.0849553026480027, 0.8247272054996396, 0.1398354475428929, 0.8390126852573574, 0.19383038074298664, 0.09691519037149332, 0.6784063326004532, 0.1318843352845641, 0.6594216764228206, 0.15177422041572924, 0.12141937633258339, 0.2731935967483126, 0.09106453224943754, 0.030354844083145847, 0.09106453224943754, 0.06070968816629169, 0.06070968816629169, 0.12141937633258339, 0.25085446934999783, 0.12542723467499892, 0.6271361733749946, 0.6310879636085946, 0.6819005182017774, 0.05682504318348145, 0.05682504318348145, 0.05682504318348145, 0.1136500863669629, 0.907955581980111, 0.1706024141146056, 0.5118072423438169, 0.11373494274307042, 0.11373494274307042, 0.05686747137153521, 0.9336787251617721, 0.24968973501008956, 0.12484486750504478, 0.6242243375252239, 0.18935333887704286, 0.7574133555081715, 0.31635644084600395, 0.10545214694866797, 0.5272607347433399, 0.8380211133617114, 0.22860931249388747, 0.13716558749633248, 0.09144372499755499, 0.045721862498777494, 0.09144372499755499, 0.27433117499266496, 0.09144372499755499, 0.045721862498777494, 0.85030142353932, 0.14171690392322, 0.8860508389497272, 0.8834695952632382, 0.08031541775120347, 0.7677601068279488, 0.6474470518206864, 0.1736180197919066, 0.05787267326396887, 0.11574534652793773, 0.11574534652793773, 0.11574534652793773, 0.11574534652793773, 0.28936336631984433, 0.6706296764653815, 0.22354322548846053, 0.24018000152073074, 0.06862285757735165, 0.06862285757735165, 0.034311428788675824, 0.06862285757735165, 0.2744914303094066, 0.1372457151547033, 0.06862285757735165, 0.3283747474846053, 0.06567494949692107, 0.06567494949692107, 0.06567494949692107, 0.39404969698152637, 0.7740086357727117, 0.2546321653515986, 0.04774353100342474, 0.07957255167237456, 0.07957255167237456, 0.04774353100342474, 0.09548706200684948, 0.11140157234132439, 0.07957255167237456, 0.07957255167237456, 0.1273160826757993, 0.5189644511784159, 0.13538203074219546, 0.06769101537109773, 0.04512734358073182, 0.06769101537109773, 0.09025468716146363, 0.02256367179036591, 0.06769101537109773, 0.14193338155405333, 0.22709341048648532, 0.05677335262162133, 0.05677335262162133, 0.08516002893243199, 0.22709341048648532, 0.028386676310810665, 0.11354670524324266, 0.05677335262162133, 0.05677335262162133, 0.2957824963479761, 0.16901856934170062, 0.042254642335425155, 0.08450928467085031, 0.2957824963479761, 0.08450928467085031, 0.042254642335425155, 0.192429749496741, 0.192429749496741, 0.0962148747483705, 0.577289248490223, 0.7066304322989998, 0.7414015727721633, 0.6726918621722672, 0.5198600714693318, 0.05776223016325908, 0.05776223016325908, 0.05776223016325908, 0.05776223016325908, 0.17328669048977724, 0.23798247822118612, 0.7139474346635584, 0.6654066156234316, 0.13856452792301827, 0.6928226396150913, 0.13856452792301827, 0.12988421689262517, 0.30306317274945876, 0.04329473896420839, 0.08658947792841679, 0.12988421689262517, 0.08658947792841679, 0.21647369482104195, 0.7821807621265149, 0.13036346035441915, 0.07314654399818522, 0.10971981599727783, 0.4023059919900187, 0.07314654399818522, 0.07314654399818522, 0.10971981599727783, 0.03657327199909261, 0.14629308799637045, 0.8435435548000875, 0.1687087109600175, 0.6322892952541505, 0.11496169004620918, 0.05748084502310459, 0.05748084502310459, 0.11496169004620918, 0.14610707192023786, 0.12175589326686488, 0.07305353596011893, 0.0974047146134919, 0.12175589326686488, 0.04870235730674595, 0.12175589326686488, 0.04870235730674595, 0.07305353596011893, 0.17045825057361083, 0.8732181360905586, 0.22293879952914203, 0.557346998822855, 0.11146939976457101, 0.11146939976457101, 0.1413830099088963, 0.7069150495444815, 0.7993819015747687, 0.8760094487057802, 0.7510943959207501, 0.12149766085039862, 0.12149766085039862, 0.7289859651023918, 0.20346311822222832, 0.610389354666685, 0.18376046095819537, 0.06125348698606513, 0.5512813828745862, 0.12250697397213026, 0.7845434853932346, 0.1854191307558687, 0.7416765230234748, 0.1627470660033147, 0.08137353300165735, 0.48824119800994414, 0.08137353300165735, 0.09979009199211054, 0.09979009199211054, 0.09979009199211054, 0.09979009199211054, 0.04989504599605527, 0.49895045996055276, 0.1593304312303671, 0.6373217249214684, 0.07966521561518355, 0.23131038913346516, 0.1831207247306599, 0.028913798641683145, 0.2409483220140262, 0.05782759728336629, 0.03855173152224419, 0.08674139592504944, 0.04818966440280524, 0.05782759728336629, 0.028913798641683145, 0.7438148356067128, 0.06120314342586627, 0.3672188605551976, 0.06120314342586627, 0.0918047151387994, 0.06120314342586627, 0.15300785856466567, 0.0918047151387994, 0.0918047151387994, 0.7278288634709607, 0.4701123944252111, 0.03134082629501407, 0.12536330518005628, 0.09402247888504221, 0.15670413147507034, 0.09402247888504221, 0.721482495467409, 0.4231897124784189, 0.11755269791067192, 0.023510539582134383, 0.11755269791067192, 0.023510539582134383, 0.047021079164268766, 0.023510539582134383, 0.09404215832853753, 0.07053161874640315, 0.047021079164268766, 0.24474039848997836, 0.5384288766779524, 0.048948079697995674, 0.048948079697995674, 0.09789615939599135, 0.07611940972154249, 0.19029852430385624, 0.19029852430385624, 0.5328358680507974, 0.8806238893045376, 0.8464099931206038, 0.10746641181823641, 0.30704689090924686, 0.09211406727277406, 0.15352344545462343, 0.09211406727277406, 0.061409378181849376, 0.015352344545462344, 0.1381711009091611, 0.015352344545462344, 0.1497842786632044, 0.09361517416450275, 0.056169104498701654, 0.24339945282770717, 0.056169104498701654, 0.056169104498701654, 0.11233820899740331, 0.056169104498701654, 0.13106124383030385, 0.0374460696658011, 0.7062053002163522, 0.29183475287606336, 0.09727825095868779, 0.12159781369835973, 0.24319562739671946, 0.024319562739671948, 0.14591737643803168, 0.024319562739671948, 0.024319562739671948, 0.024319562739671948, 0.8443795748177979, 0.19582025569349204, 0.09791012784674602, 0.09791012784674602, 0.5874607670804761, 0.07587468238741754, 0.22762404716225265, 0.4552480943245053, 0.15174936477483508, 0.07587468238741754, 0.07587468238741754, 0.11391986809765343, 0.11391986809765343, 0.06835192085859206, 0.432895498771083, 0.06835192085859206, 0.04556794723906137, 0.06835192085859206, 0.06835192085859206, 0.19980510493867706, 0.5994153148160313, 0.8085794474407633, 0.8597559247788851, 0.6483886272545429, 0.1591122417780464, 0.6364489671121856, 0.7644747730268778, 0.7434498549950338, 0.11437690076846674, 0.05718845038423337, 0.08992522588590866, 0.08992522588590866, 0.05995015059060577, 0.11990030118121155, 0.08992522588590866, 0.05995015059060577, 0.32972582824833174, 0.08992522588590866, 0.08992522588590866, 0.8500643981717215, 0.0896837651709262, 0.1345256477563893, 0.1793675303418524, 0.4932607084400941, 0.1345256477563893, 0.18310276393210329, 0.12206850928806885, 0.427239782508241, 0.061034254644034426, 0.061034254644034426, 0.12206850928806885, 0.8464270684715073, 0.09818252754097122, 0.19636505508194244, 0.19636505508194244, 0.4909126377048561, 0.15591551787064628, 0.06236620714825851, 0.18709862144477551, 0.18709862144477551, 0.12473241429651702, 0.09354931072238776, 0.12473241429651702, 0.031183103574129255, 0.18477376408615473, 0.18477376408615473, 0.1478190112689238, 0.03695475281723095, 0.03695475281723095, 0.2956380225378476, 0.03695475281723095, 0.0739095056344619, 0.03695475281723095, 0.07412497541893183, 0.5188748279325228, 0.07412497541893183, 0.14824995083786366, 0.07412497541893183, 0.07412497541893183, 0.1458875221597639, 0.07294376107988194, 0.5835500886390556, 0.1458875221597639, 0.10082697110277822, 0.20165394220555644, 0.05041348555138911, 0.15124045665416733, 0.15124045665416733, 0.2520674277569456, 0.5970014216816373, 0.7645993105047725, 0.7596090485662513, 0.09495113107078142, 0.10627595563184666, 0.21255191126369333, 0.10627595563184666, 0.10627595563184666, 0.42510382252738665, 0.33605370665437345, 0.11201790221812448, 0.5600895110906224, 0.6777379549746673, 0.7521846909212765, 0.2149099116917933, 0.8273838104231036, 0.11819768720330051, 0.8759697844686901, 0.04726551768291409, 0.18906207073165637, 0.14179655304874228, 0.14179655304874228, 0.04726551768291409, 0.37812414146331275, 0.09453103536582819, 0.7450054724332756, 0.09601257454794632, 0.04800628727397316, 0.04800628727397316, 0.14401886182191947, 0.2400314363698658, 0.28803772364383895, 0.04800628727397316, 0.9234117171715538, 0.17946686643325596, 0.17946686643325596, 0.08973343321662798, 0.5384005992997679, 0.8437620878198931, 0.9212738886387055, 0.6570626000785228, 0.1642656500196307, 0.34759212540059903, 0.04965601791437129, 0.04965601791437129, 0.29793610748622773, 0.09931203582874258, 0.04965601791437129, 0.04965601791437129, 0.9181570430957057, 0.8516448020405316, 0.16991609079941603, 0.509748272398248, 0.254874136199124, 0.8619654785203038, 0.8895251773744752, 0.7972169467015426, 0.6584714871432025, 0.16461787178580062, 0.6212193875088484, 0.27902981505231234, 0.6975745376307808, 0.7955333049265456, 0.11364761498950653, 0.22043243015032832, 0.38575675276307453, 0.08266216130637312, 0.08266216130637312, 0.05510810753758208, 0.08266216130637312, 0.05510810753758208, 0.7978062984931246, 0.8014228181608289, 0.1648135469548633, 0.1648135469548633, 0.6592541878194532, 0.09147613076250098, 0.18295226152500196, 0.09147613076250098, 0.4573806538125049, 0.13721419614375147, 0.7003489625011455, 0.7910213305547856, 0.9402135678855332, 0.5709521648286748, 0.2854760824143374, 0.07136902060358435, 0.29562373685442167, 0.10557990601943631, 0.08446392481554904, 0.04223196240777452, 0.08446392481554904, 0.04223196240777452, 0.04223196240777452, 0.10557990601943631, 0.23227579324275988, 0.1639753197142587, 0.8198765985712935, 0.11408881961130209, 0.22817763922260417, 0.05704440980565104, 0.05704440980565104, 0.5704440980565104, 0.08206513088365147, 0.6565210470692118, 0.08206513088365147, 0.08206513088365147, 0.2712835184742105, 0.2712835184742105, 0.049324276086220094, 0.1479728282586603, 0.049324276086220094, 0.07398641412933014, 0.07398641412933014, 0.049324276086220094, 0.7912497428258081, 0.11303567754654402, 0.7377512554227142, 0.08197236171363492, 0.08197236171363492, 0.08197236171363492, 0.8783670246698043, 0.5055453070294851, 0.1579829084467141, 0.06319316337868564, 0.09478974506802845, 0.03159658168934282, 0.09478974506802845, 0.03159658168934282, 0.27378571856404377, 0.16427143113842627, 0.43805714970247, 0.05475714371280875, 0.14484292192722498, 0.7242146096361248, 0.14484292192722498, 0.14622992286931927, 0.7311496143465963, 0.3499420050330107, 0.11664733501100356, 0.46658934004401426, 0.1612269690157233, 0.1612269690157233, 0.08061348450786165, 0.08061348450786165, 0.08061348450786165, 0.4030674225393083, 0.15205381336021725, 0.07602690668010863, 0.45616144008065174, 0.07602690668010863, 0.07602690668010863, 0.15205381336021725, 0.6456315216977059, 0.6452937712096602, 0.21509792373655343, 0.8183489609088572, 0.10174298829078998, 0.7122009180355299, 0.10174298829078998, 0.1601027458209285, 0.8005137291046426, 0.31003695829369615, 0.06200739165873923, 0.06200739165873923, 0.49605913326991385, 0.12401478331747846, 0.14403792431147958, 0.7201896215573979, 0.7493020717233315, 0.8429711306047506, 0.06484393312344235, 0.06484393312344235, 0.6193052116405695, 0.8756143451836733, 0.8008688795192291, 0.13179015505559888, 0.24161528426859794, 0.021965025842599812, 0.021965025842599812, 0.043930051685199624, 0.043930051685199624, 0.28554533595379755, 0.08786010337039925, 0.06589507752779944, 0.7022101724357698, 0.2601417676543885, 0.0520283535308777, 0.2081134141235108, 0.0520283535308777, 0.2601417676543885, 0.1040567070617554, 0.10737917517449751, 0.046019646503356076, 0.07669941083892678, 0.07669941083892678, 0.046019646503356076, 0.015339882167785358, 0.09203929300671215, 0.35281728985906324, 0.07669941083892678, 0.10737917517449751, 0.7313451569631558, 0.21485642689890383, 0.42971285379780766, 0.04297128537978077, 0.08594257075956153, 0.21485642689890383, 0.8617536078620927, 0.08300848803433578, 0.16601697606867155, 0.7055721482918541, 0.04150424401716789, 0.25103680292093217, 0.20539374784439907, 0.15975069276786594, 0.11410763769133281, 0.1369291652295994, 0.04564305507653312, 0.04564305507653312, 0.06091583596552208, 0.0761447949569026, 0.4720977287327961, 0.01522895899138052, 0.01522895899138052, 0.0761447949569026, 0.06091583596552208, 0.12183167193104416, 0.06091583596552208, 0.03045791798276104, 0.7651946224443958, 0.5319802264879686, 0.13299505662199215, 0.04433168554066405, 0.04433168554066405, 0.04433168554066405, 0.13299505662199215, 0.04433168554066405, 0.04433168554066405, 0.7883855419255812, 0.6621634979568944, 0.24326500951298666, 0.72979502853896, 0.7396153557238562, 0.12326922595397603, 0.12326922595397603, 0.08134052907261678, 0.12201079360892518, 0.12201079360892518, 0.04067026453630839, 0.04067026453630839, 0.4880431744357007, 0.12201079360892518, 0.8963059489863406, 0.803400236241231, 0.8763928533486199, 0.7943436867340646, 0.9057287714195044, 0.06469491224425031, 0.06469491224425031, 0.9359029338140855, 0.7857459611032408, 0.6207836552245471, 0.0736687472570582, 0.22100624177117462, 0.5893499780564656, 0.7841167624950095, 0.206224840830385, 0.09165548481350444, 0.09165548481350444, 0.11456935601688056, 0.06874161361012833, 0.11456935601688056, 0.06874161361012833, 0.13748322722025666, 0.04582774240675222, 0.06874161361012833, 0.23130361626848914, 0.07710120542282971, 0.5397084379598079, 0.15420241084565942, 0.7091952664507386, 0.9537593503185158, 0.7598964895411777, 0.11293953895959048, 0.09035163116767239, 0.15811535454342668, 0.06776372337575429, 0.06776372337575429, 0.022587907791918098, 0.045175815583836196, 0.022587907791918098, 0.36140652467068957, 0.06776372337575429, 0.8038153644283503, 0.43739110410199467, 0.1611440909849454, 0.06906175327926231, 0.09208233770568308, 0.06906175327926231, 0.02302058442642077, 0.06906175327926231, 0.06906175327926231, 0.09446506566619968, 0.09446506566619968, 0.5667903939971981, 0.09446506566619968, 0.09446506566619968, 0.2137320697853, 0.15266576413235713, 0.30533152826471427, 0.030533152826471427, 0.030533152826471427, 0.061066305652942854, 0.09159945847941428, 0.061066305652942854, 0.08822747089678373, 0.029409156965594575, 0.029409156965594575, 0.8234563950366481, 0.029409156965594575, 0.20745161982564342, 0.10372580991282171, 0.6223548594769303, 0.3150927717221043, 0.06301855434442086, 0.06301855434442086, 0.44112988041094603, 0.06301855434442086, 0.22555666569734556, 0.11277833284867278, 0.5638916642433639, 0.5875348332630401, 0.6214087587324154, 0.04827235603207117, 0.04827235603207117, 0.09654471206414234, 0.7723576965131387, 0.14627149713222787, 0.4388144913966836, 0.1097036228491709, 0.03656787428305697, 0.14627149713222787, 0.1097036228491709, 0.22048704139623881, 0.12765039238729617, 0.08123206788282483, 0.04641832450447133, 0.12765039238729617, 0.04641832450447133, 0.18567329801788532, 0.034813743378353496, 0.058022905630589164, 0.06962748675670699, 0.18215042606023152, 0.09107521303011576, 0.7286017042409261, 0.8529179958049812, 0.9115646518301469, 0.6463035297202414, 0.7477543242653998, 0.14955086485307997, 0.14955086485307997, 0.6938927913100557, 0.766866412817046, 0.17151019842955761, 0.22868026457274346, 0.17151019842955761, 0.17151019842955761, 0.28585033071592936, 0.7271227117633965, 0.1432581015932687, 0.6446614571697092, 0.07162905079663436, 0.10744357619495154, 0.6677251732354814, 0.22257505774516045, 0.3067030006289339, 0.19716621469002893, 0.10953678593890497, 0.08762942875112398, 0.04381471437556199, 0.08762942875112398, 0.021907357187780994, 0.08762942875112398, 0.04381471437556199, 0.021907357187780994, 0.13219497677728845, 0.5287799071091538, 0.13219497677728845, 0.19829246516593266, 0.18617375095314112, 0.5119778151211382, 0.04654343773828528, 0.13963031321485586, 0.04654343773828528, 0.10285995236769065, 0.5142997618384533, 0.2057199047353813, 0.6173472736607132, 0.5915628239684269, 0.09243169124506669, 0.01848633824901334, 0.07394535299605336, 0.09243169124506669, 0.01848633824901334, 0.055459014747040014, 0.055459014747040014, 0.01848633824901334, 0.5029997664229552, 0.08982138686124198, 0.1257499416057388, 0.05389283211674519, 0.10778566423349038, 0.05389283211674519, 0.017964277372248396, 0.017964277372248396, 0.017964277372248396, 0.09644922643961876, 0.6751445850773313, 0.09644922643961876, 0.09644922643961876, 0.4878252067524992, 0.22765176315116628, 0.03252168045016661, 0.09756504135049984, 0.06504336090033322, 0.03252168045016661, 0.03252168045016661, 0.03252168045016661, 0.8461947860348354, 0.1792639889250247, 0.5377919667750741, 0.1792639889250247, 0.15351516218811925, 0.15351516218811925, 0.03070303243762385, 0.09210909731287155, 0.09210909731287155, 0.15351516218811925, 0.27632729193861466, 0.0614060648752477, 0.7417022856679424, 0.7264792918773474, 0.9017592374995074, 0.1704321287405045, 0.681728514962018, 0.7038750516616561, 0.2955971565948683, 0.07389928914871707, 0.07389928914871707, 0.5172950240410195, 0.830536436258409, 0.22923297763927158, 0.17192473322945367, 0.028654122204908948, 0.057308244409817896, 0.057308244409817896, 0.08596236661472684, 0.3151953442539984, 0.057308244409817896, 0.7400388284516717, 0.6698836484339764, 0.1674709121084941, 0.8094708617566407, 0.6049923266951129, 0.11343606125533368, 0.11343606125533368, 0.03781202041844456, 0.07562404083688912, 0.03781202041844456, 0.7545593143234798, 0.18863982858086994, 0.21570612986291823, 0.05392653246572956, 0.05392653246572956, 0.6471183895887548, 0.7587317177723828, 0.1896829294430957, 0.22944701876488352, 0.11472350938244176, 0.5736175469122088, 0.8959275343679842, 0.21221232937821397, 0.07073744312607132, 0.07073744312607132, 0.42442465875642793, 0.07073744312607132, 0.14147488625214263, 0.07073744312607132, 0.12614657884333977, 0.12614657884333977, 0.6307328942166989, 0.49553791600434904, 0.0495537916004349, 0.0495537916004349, 0.0991075832008698, 0.1486613748013047, 0.0991075832008698, 0.22846361333897647, 0.6853908400169294, 0.7321200840810927, 0.1609000218786781, 0.23241114271364616, 0.08938890104371006, 0.1251444614611941, 0.05363334062622604, 0.035755560417484025, 0.05363334062622604, 0.035755560417484025, 0.10726668125245208, 0.08938890104371006, 0.13664201737387652, 0.13664201737387652, 0.7515310955563208, 0.7781904321136776, 0.1945476080284194, 0.7774087778423597, 0.19435219446058993, 0.8343359012035203, 0.12853966198802677, 0.06426983099401339, 0.7712379719281606, 0.7467506006285708, 0.3691949344775222, 0.43072742355710925, 0.12306497815917407, 0.061532489079587034, 0.061532489079587034, 0.1959642570648537, 0.7838570282594148, 0.6704299547695283, 0.8904644728609773, 0.8079728159935367, 0.18632024495670116, 0.12421349663780078, 0.06210674831890039, 0.6210674831890038, 0.18937502551346205, 0.18937502551346205, 0.5681250765403862, 0.13654347130443942, 0.8192608278266366, 0.05655009111127163, 0.3958506377789014, 0.16965027333381488, 0.11310018222254326, 0.11310018222254326, 0.16965027333381488, 0.18789700670456727, 0.04697425167614182, 0.07046137751421273, 0.07046137751421273, 0.09394850335228364, 0.02348712583807091, 0.02348712583807091, 0.44625539092334726, 0.02348712583807091, 0.846137272564773, 0.6750604254121636, 0.7464722518682468, 0.12441204197804115, 0.6384483695005237, 0.19549146222352803, 0.5864743866705842, 0.09774573111176402, 0.09774573111176402, 0.0988779969934878, 0.1483169954902317, 0.0988779969934878, 0.0988779969934878, 0.07415849774511585, 0.07415849774511585, 0.24719499248371948, 0.0494389984967439, 0.0988779969934878, 0.6730691362327895, 0.13360598031032078, 0.07634627446304044, 0.13360598031032078, 0.05725970584728034, 0.26721196062064156, 0.05725970584728034, 0.03817313723152022, 0.11451941169456067, 0.09543284307880055, 0.03817313723152022, 0.09678897153976333, 0.09678897153976333, 0.09678897153976333, 0.58073382923858, 0.6262451835345194, 0.11051385591785637, 0.07367590394523758, 0.03683795197261879, 0.11051385591785637, 0.6098215083654501, 0.9113811381936753, 0.18458566801833876, 0.11075140081100325, 0.03691713360366775, 0.33225420243300974, 0.055375700405501625, 0.18458566801833876, 0.018458566801833876, 0.018458566801833876, 0.03691713360366775, 0.7287729171295154, 0.12280173406157967, 0.061400867030789834, 0.061400867030789834, 0.49120693624631867, 0.24560346812315934, 0.2743898796402892, 0.3429873495503615, 0.051448102432554224, 0.03429873495503615, 0.03429873495503615, 0.10289620486510845, 0.051448102432554224, 0.08574683738759037, 0.017149367477518076, 0.499040967865535, 0.18146944286019454, 0.045367360715048634, 0.045367360715048634, 0.045367360715048634, 0.1361020821451459, 0.045367360715048634, 0.6661932470686202, 0.1984756972223643, 0.09923784861118215, 0.09923784861118215, 0.09923784861118215, 0.4961892430559107, 0.22811283796610654, 0.5132538854237397, 0.057028209491526635, 0.11405641898305327, 0.8083347860774066, 0.7613466255178731, 0.8865549057449253, 0.871383493287764, 0.6203834199794294, 0.1283364341083396, 0.2566728682166792, 0.1283364341083396, 0.320841085270849, 0.0320841085270849, 0.09625232558125468, 0.0641682170541698, 0.26825718847010405, 0.40238578270515607, 0.033532148558763006, 0.10059644567628902, 0.10059644567628902, 0.06706429711752601, 0.033532148558763006, 0.7273163300918175, 0.08828392388866665, 0.1765678477773333, 0.08828392388866665, 0.4414196194433333, 0.08828392388866665, 0.6649587859445634, 0.15629388612886536, 0.234440829193298, 0.5470286014510287, 0.8129252754461084, 0.16057820815068224, 0.16057820815068224, 0.642312832602729, 0.7536539139229422, 0.08792653647983582, 0.08792653647983582, 0.8792653647983583, 0.8118120953097087, 0.1910123826285381, 0.7640495305141524, 0.15171881697249714, 0.15171881697249714, 0.6068752678899886, 0.0437130478564971, 0.0874260957129942, 0.0874260957129942, 0.0437130478564971, 0.437130478564971, 0.0874260957129942, 0.0437130478564971, 0.1311391435694913, 0.0437130478564971, 0.15385261078677318, 0.23077891618015978, 0.07692630539338659, 0.038463152696693294, 0.07692630539338659, 0.23077891618015978, 0.11538945809007989, 0.07692630539338659, 0.038463152696693294, 0.24943889115480905, 0.12471944557740453, 0.6235972278870227, 0.8562943448632201, 0.08562943448632201, 0.08129970354455764, 0.12194955531683645, 0.20324925886139408, 0.16259940708911527, 0.2845489624059517, 0.12194955531683645, 0.04064985177227882, 0.22441506163020908, 0.6732451848906272, 0.06970768560374031, 0.7667845416411435, 0.06970768560374031, 0.7283692159456189, 0.10405274513508841, 0.2244384763110534, 0.15538048359996004, 0.08632249088886669, 0.017264498177773337, 0.08632249088886669, 0.051793494533320016, 0.06905799271109335, 0.2244384763110534, 0.06905799271109335, 0.017264498177773337, 0.7625666333290094, 0.22502086906673127, 0.16876565180004846, 0.05625521726668282, 0.3375313036000969, 0.05625521726668282, 0.11251043453336564, 0.14562197642065883, 0.7281098821032941, 0.6637643322983676, 0.13275286645967355, 0.7655574198120778, 0.8049646044378144, 0.822219800512868, 0.08098538451404445, 0.08098538451404445, 0.1619707690280889, 0.5668976915983112, 0.7906875220219726, 0.03862157728514573, 0.23172946371087436, 0.03862157728514573, 0.03862157728514573, 0.424837350136603, 0.07724315457029146, 0.07724315457029146, 0.11552794327609885, 0.11552794327609885, 0.11552794327609885, 0.11552794327609885, 0.4621117731043954, 0.8580575378344703, 0.30303258542733974, 0.10822592336690705, 0.06493555402014423, 0.08658073869352564, 0.2164518467338141, 0.02164518467338141, 0.10822592336690705, 0.06493555402014423, 0.07503596878820966, 0.03751798439410483, 0.11255395318231448, 0.15007193757641932, 0.11255395318231448, 0.07503596878820966, 0.22510790636462896, 0.07503596878820966, 0.18758992197052415, 0.18222090015556475, 0.728883600622259, 0.3557904860477386, 0.09578974624362192, 0.06842124731687281, 0.013684249463374562, 0.09578974624362192, 0.15052674409712016, 0.04105274839012368, 0.05473699785349825, 0.06842124731687281, 0.06842124731687281, 0.15830169033287986, 0.21106892044383982, 0.10553446022191991, 0.42213784088767964, 0.052767230110959955, 0.6708507590391636, 0.12941603912624827, 0.7764962347574897, 0.1400278326301646, 0.0700139163150823, 0.0700139163150823, 0.5601113305206584, 0.1400278326301646, 0.12227394203800608, 0.06987082402171776, 0.10480623603257663, 0.06987082402171776, 0.36682182611401826, 0.052403118016288316, 0.03493541201085888, 0.0873385300271472, 0.03493541201085888, 0.052403118016288316, 0.12808234275239497, 0.5763705423857773, 0.19212351412859244, 0.14888568289168733, 0.07444284144584366, 0.29777136578337465, 0.14888568289168733, 0.14888568289168733, 0.07444284144584366, 0.07444284144584366, 0.32841609419449824, 0.12315603532293684, 0.10947203139816608, 0.10947203139816608, 0.0684200196238538, 0.05473601569908304, 0.05473601569908304, 0.0684200196238538, 0.02736800784954152, 0.04105201177431228, 0.14725970845615835, 0.7362985422807918, 0.9000760281376406, 0.17236213602563866, 0.129271602019229, 0.043090534006409664, 0.129271602019229, 0.043090534006409664, 0.08618106801281933, 0.3447242720512773, 0.043090534006409664, 0.0767593897751172, 0.0767593897751172, 0.5373157284258204, 0.0767593897751172, 0.1535187795502344, 0.7135753008795288, 0.6234685445114683, 0.8787317459117997, 0.2904313343247053, 0.5808626686494106, 0.7575507197999585, 0.18938767994998962, 0.15220867965136264, 0.15220867965136264, 0.11415650973852198, 0.07610433982568132, 0.11415650973852198, 0.10147245310090842, 0.1395246230137491, 0.07610433982568132, 0.025368113275227106, 0.05073622655045421, 0.6477794071272184, 0.1619448517818046, 0.12549790942623837, 0.8784853659836684, 0.7524930686570117, 0.17765163934088057, 0.17765163934088057, 0.11843442622725371, 0.41452049179538797, 0.059217213113626856, 0.1502270570751271, 0.5257946997629448, 0.07511352853756355, 0.1502270570751271, 0.43546993413902024, 0.036289161178251685, 0.07257832235650337, 0.036289161178251685, 0.2903132894260135, 0.036289161178251685, 0.036289161178251685, 0.036289161178251685, 0.16621179320597598, 0.6648471728239039, 0.7553453056010918, 0.06608818963958271, 0.06608818963958271, 0.8591464653145753, 0.06608818963958271, 0.16364768838227223, 0.6545907535290889, 0.7168054788212574, 0.7543028719859366, 0.6272864390841144, 0.8778613472808339, 0.06099153737975351, 0.9148730606963027, 0.7454013951742077, 0.18635034879355192, 0.6977717167963903, 0.2759448475838759, 0.5518896951677518, 0.17621607107088816, 0.3524321421417763, 0.03524321421417763, 0.07048642842835526, 0.03524321421417763, 0.03524321421417763, 0.1057296426425329, 0.1057296426425329, 0.03524321421417763, 0.03524321421417763, 0.731177776132225, 0.794748464180975, 0.7530848165601824, 0.18223349708301442, 0.7289339883320577, 0.8184454452333125, 0.6976454446456796, 0.823503046402191, 0.10293788080027387, 0.10293788080027387, 0.1392504110191227, 0.5570016440764908, 0.20887561652868403, 0.06962520550956135, 0.8805022437032233, 0.6907851489643596, 0.1180930911168115, 0.17713963667521726, 0.14761636389601437, 0.29523272779202875, 0.029523272779202876, 0.1180930911168115, 0.029523272779202876, 0.05904654555840575, 0.029523272779202876, 0.1337358059406292, 0.04457860198020973, 0.08915720396041946, 0.04457860198020973, 0.40120741782188757, 0.1783144079208389, 0.08915720396041946, 0.04457860198020973, 0.31616237811677095, 0.6323247562335419, 0.6931904004121892, 0.184460205882125, 0.16140268014685938, 0.34586288602898435, 0.04611505147053125, 0.04611505147053125, 0.023057525735265625, 0.023057525735265625, 0.023057525735265625, 0.0922301029410625, 0.023057525735265625, 0.2807440190265418, 0.15313310128720461, 0.05104436709573487, 0.17865528483507204, 0.10208873419146974, 0.025522183547867436, 0.025522183547867436, 0.12761091773933717, 0.025522183547867436, 0.113010915652633, 0.113010915652633, 0.113010915652633, 0.6780654939157981, 0.8549441164566208, 0.18012822146852786, 0.24017096195803714, 0.12008548097901857, 0.3602564429370557, 0.11648587469000189, 0.11648587469000189, 0.6989152481400114, 0.8545710733637153, 0.12525741273153929, 0.12525741273153929, 0.3757722381946178, 0.12525741273153929, 0.12525741273153929, 0.06262870636576964, 0.09214312637453712, 0.09214312637453712, 0.09214312637453712, 0.09214312637453712, 0.09214312637453712, 0.5528587582472226, 0.13345914545079027, 0.8007548727047417, 0.14156765569857882, 0.707838278492894, 0.3032222137454494, 0.10107407124848312, 0.12634258906060392, 0.05053703562424156, 0.07580555343636235, 0.05053703562424156, 0.17687962468484547, 0.10107407124848312, 0.02526851781212078, 0.09314501689489563, 0.18629003378979125, 0.46572508447447813, 0.09314501689489563, 0.09314501689489563, 0.33670938944575807, 0.056118231574293014, 0.056118231574293014, 0.33670938944575807, 0.056118231574293014, 0.056118231574293014, 0.11223646314858603, 0.056118231574293014, 0.8676750191047813, 0.27468910280918896, 0.6867227570229725, 0.22086369738905376, 0.13251821843343226, 0.30920917634467526, 0.04417273947781075, 0.13251821843343226, 0.0883454789556215, 0.0883454789556215, 0.7076230884529329, 0.07076230884529329, 0.07076230884529329, 0.14152461769058658, 0.9026487962867352, 0.8984639464086159, 0.08167854058260145, 0.12410146831764286, 0.12410146831764286, 0.7446088099058571, 0.1257332767451773, 0.06286663837258866, 0.1257332767451773, 0.18859991511776597, 0.37719983023553194, 0.1257332767451773, 0.15521350563642194, 0.6208540225456878, 0.15521350563642194, 0.17055014639168767, 0.6822005855667507, 0.1590344007567207, 0.10602293383781382, 0.10602293383781382, 0.4771032022701622, 0.05301146691890691, 0.23029322807495708, 0.3454398421124356, 0.06579806516427346, 0.06579806516427346, 0.04934854887320509, 0.03289903258213673, 0.04934854887320509, 0.04934854887320509, 0.03289903258213673, 0.04934854887320509, 0.7039541134658683, 0.20520021475589004, 0.6840007158529668, 0.06840007158529668, 0.06840007158529668, 0.17172738541230081, 0.6869095416492033, 0.7013400888320832, 0.14026801776641665, 0.8919312567751462], \"Term\": [\"absolut\", \"absolut\", \"absolut\", \"absolut\", \"absolut\", \"absolut\", \"act\", \"act\", \"act\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"actual\", \"ad\", \"ad\", \"afford\", \"agenc\", \"agre\", \"aliv\", \"almost\", \"almost\", \"almost\", \"almost\", \"almost\", \"alreadi\", \"alreadi\", \"alreadi\", \"alreadi\", \"alreadi\", \"alreadi\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"also\", \"alway\", \"alway\", \"alway\", \"alway\", \"alway\", \"alway\", \"alway\", \"analysi\", \"angl\", \"angri\", \"anim\", \"anthem\", \"anybodi\", \"anyon\", \"anyon\", \"anyon\", \"anyon\", \"anyon\", \"anyon\", \"anyon\", \"anyon\", \"anyway\", \"anyway\", \"anyway\", \"anyway\", \"anywher\", \"appar\", \"appropri\", \"aspect\", \"assassin\", \"assist\", \"assist\", \"assist\", \"athlet\", \"athlet\", \"athlet\", \"athlet\", \"athlet\", \"attent\", \"averag\", \"averag\", \"averag\", \"averag\", \"averag\", \"away\", \"away\", \"away\", \"away\", \"away\", \"awkward\", \"babi\", \"babi\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"back\", \"backward\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"ball\", \"ball\", \"ball\", \"ball\", \"ball\", \"ball\", \"bar\", \"basketbal\", \"basketbal\", \"basketbal\", \"basketbal\", \"basketbal\", \"basketbal\", \"basketbal\", \"basketbal\", \"basketbal\", \"bathroom\", \"beach\", \"beat\", \"beat\", \"beat\", \"beat\", \"begun\", \"behind\", \"behind\", \"behind\", \"behind\", \"behind\", \"believ\", \"believ\", \"believ\", \"believ\", \"believ\", \"ben\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"best\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"better\", \"big\", \"big\", \"big\", \"big\", \"big\", \"big\", \"biggest\", \"biggest\", \"biggest\", \"bird\", \"bird\", \"block\", \"block\", \"block\", \"blood\", \"blow\", \"blown\", \"booker\", \"booti\", \"bosh\", \"bosh\", \"bosh\", \"bosh\", \"boston\", \"boston\", \"boston\", \"bout\", \"bout\", \"bout\", \"bowl\", \"boy\", \"break\", \"break\", \"break\", \"break\", \"break\", \"breath\", \"brother\", \"brother\", \"brown\", \"bum\", \"bum\", \"bunch\", \"bunch\", \"bunch\", \"buy\", \"call\", \"call\", \"call\", \"call\", \"call\", \"cant\", \"cant\", \"cant\", \"cant\", \"cant\", \"cant\", \"cant\", \"cant\", \"cant\", \"care\", \"care\", \"care\", \"care\", \"cast\", \"cast\", \"casual\", \"celebr\", \"chanc\", \"chanc\", \"chanc\", \"chanc\", \"chanc\", \"check\", \"chemistri\", \"chemistri\", \"chicken\", \"chill\", \"chill\", \"chose\", \"circl\", \"citi\", \"citi\", \"class\", \"classic\", \"closer\", \"club\", \"club\", \"coach\", \"coach\", \"coach\", \"coach\", \"cole\", \"combin\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"come\", \"commentari\", \"commission\", \"compar\", \"compet\", \"confirm\", \"confirm\", \"confirm\", \"contest\", \"contest\", \"contract\", \"contract\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"cool\", \"correct\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"could\", \"cours\", \"cours\", \"crack\", \"cramp\", \"crazi\", \"crazi\", \"crazi\", \"crazi\", \"crazi\", \"crazi\", \"crazi\", \"crazi\", \"credibl\", \"crown\", \"curri\", \"curri\", \"curri\", \"curri\", \"curri\", \"curri\", \"cute\", \"dame\", \"damn\", \"damn\", \"damn\", \"damn\", \"damn\", \"damn\", \"damn\", \"dan\", \"dan\", \"danc\", \"date\", \"day\", \"day\", \"day\", \"day\", \"day\", \"day\", \"deal\", \"deal\", \"deal\", \"death\", \"decis\", \"decis\", \"decis\", \"decis\", \"deep\", \"defens\", \"defens\", \"defens\", \"defens\", \"defens\", \"defens\", \"defens\", \"derrick\", \"dick\", \"dick\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"didnt\", \"die\", \"dirk\", \"dirk\", \"dirk\", \"dirti\", \"dis\", \"discuss\", \"dog\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"dont\", \"doubl\", \"doubl\", \"doubl\", \"doubt\", \"doubt\", \"doubt\", \"draft\", \"draft\", \"draft\", \"dray\", \"dream\", \"dream\", \"dribbl\", \"dribbl\", \"dribbl\", \"drop\", \"drop\", \"dude\", \"dude\", \"dude\", \"dude\", \"dude\", \"dude\", \"dude\", \"dude\", \"dude\", \"dumb\", \"dumb\", \"dumb\", \"dun\", \"dunk\", \"dunk\", \"dunk\", \"dunk\", \"dunk\", \"duo\", \"durant\", \"durant\", \"durant\", \"durant\", \"durant\", \"ear\", \"earli\", \"earli\", \"earli\", \"earth\", \"earth\", \"easili\", \"easili\", \"easili\", \"eastern\", \"edit\", \"edit\", \"edit\", \"edit\", \"edit\", \"edit\", \"edit\", \"edit\", \"effici\", \"effici\", \"eh\", \"either\", \"either\", \"elbow\", \"elimin\", \"els\", \"els\", \"els\", \"els\", \"els\", \"els\", \"els\", \"em\", \"em\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"end\", \"enough\", \"enough\", \"enough\", \"enough\", \"enough\", \"epic\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"even\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"ever\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everi\", \"everyon\", \"everyon\", \"everyon\", \"everyon\", \"everyon\", \"everyon\", \"everyon\", \"exact\", \"exact\", \"exact\", \"exact\", \"exagger\", \"exampl\", \"expos\", \"face\", \"face\", \"face\", \"face\", \"face\", \"face\", \"fals\", \"fals\", \"fam\", \"famili\", \"famili\", \"famili\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"fan\", \"father\", \"father\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"field\", \"field\", \"final\", \"final\", \"final\", \"final\", \"final\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"first\", \"fish\", \"five\", \"five\", \"five\", \"five\", \"flat\", \"flat\", \"flip\", \"footbal\", \"forgot\", \"form\", \"form\", \"form\", \"format\", \"format\", \"foul\", \"foul\", \"foul\", \"foul\", \"found\", \"franchis\", \"franchis\", \"full\", \"full\", \"full\", \"full\", \"fun\", \"fun\", \"fun\", \"fun\", \"fun\", \"fun\", \"funni\", \"funni\", \"funni\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"game\", \"garbag\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"girl\", \"give\", \"give\", \"give\", \"give\", \"give\", \"give\", \"glorious\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"go\", \"goat\", \"goat\", \"goat\", \"goat\", \"goat\", \"god\", \"god\", \"god\", \"god\", \"gon\", \"gone\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"good\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"got\", \"grade\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"great\", \"griffin\", \"guard\", \"guard\", \"guard\", \"guard\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"guess\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"hair\", \"hair\", \"hairlin\", \"halfway\", \"hammer\", \"handl\", \"handl\", \"handshak\", \"happen\", \"happen\", \"happen\", \"harden\", \"harden\", \"harden\", \"harden\", \"harden\", \"harden\", \"harden\", \"harden\", \"harden\", \"hart\", \"hate\", \"hate\", \"hate\", \"hate\", \"hate\", \"head\", \"head\", \"head\", \"head\", \"head\", \"head\", \"headband\", \"hear\", \"hear\", \"hear\", \"hear\", \"heat\", \"heat\", \"heat\", \"heat\", \"heat\", \"heat\", \"heat\", \"heat\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"hell\", \"help\", \"help\", \"help\", \"help\", \"help\", \"help\", \"hey\", \"hey\", \"hey\", \"hey\", \"high\", \"high\", \"high\", \"high\", \"high\", \"high\", \"highest\", \"hire\", \"histori\", \"histori\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"holi\", \"holi\", \"holi\", \"hour\", \"hous\", \"hous\", \"hurt\", \"hurt\", \"icon\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"id\", \"imag\", \"imagin\", \"imagin\", \"imagin\", \"imagin\", \"imagin\", \"imagin\", \"imagin\", \"immedi\", \"impress\", \"impress\", \"impress\", \"impress\", \"incom\", \"individu\", \"injur\", \"injur\", \"insan\", \"insan\", \"insan\", \"insan\", \"insan\", \"insan\", \"insan\", \"insid\", \"instinct\", \"interest\", \"interest\", \"interest\", \"jam\", \"jersey\", \"jimmi\", \"job\", \"job\", \"joey\", \"join\", \"join\", \"joke\", \"joke\", \"jordan\", \"jordan\", \"jordan\", \"jordan\", \"jordan\", \"jordan\", \"jordan\", \"journal\", \"judg\", \"kat\", \"kat\", \"kat\", \"keep\", \"keep\", \"keep\", \"keep\", \"keep\", \"key\", \"killer\", \"king\", \"knew\", \"knew\", \"knew\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"know\", \"kyle\", \"kyle\", \"lanc\", \"lanc\", \"lanc\", \"lanc\", \"lanc\", \"larri\", \"larri\", \"larri\", \"larri\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"last\", \"later\", \"later\", \"laugh\", \"laugh\", \"laugh\", \"laugh\", \"leader\", \"leagu\", \"leagu\", \"leagu\", \"leagu\", \"leagu\", \"leagu\", \"leagu\", \"leav\", \"leav\", \"leav\", \"leav\", \"legaci\", \"legaci\", \"legaci\", \"legend\", \"legend\", \"legit\", \"legit\", \"legit\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"life\", \"life\", \"life\", \"life\", \"life\", \"life\", \"light\", \"like\", \"like\", \"lin\", \"line\", \"line\", \"line\", \"link\", \"link\", \"list\", \"list\", \"list\", \"list\", \"list\", \"listen\", \"listen\", \"lit\", \"liter\", \"liter\", \"liter\", \"lob\", \"locker\", \"longer\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lord\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"lose\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"love\", \"luck\", \"lue\", \"lue\", \"lue\", \"lue\", \"lue\", \"luke\", \"magic\", \"magic\", \"magic\", \"magic\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"make\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"man\", \"manag\", \"mani\", \"mani\", \"mani\", \"mani\", \"mani\", \"mani\", \"mani\", \"mani\", \"martin\", \"math\", \"matter\", \"matter\", \"may\", \"may\", \"may\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"meanwhil\", \"memori\", \"mike\", \"miller\", \"million\", \"million\", \"million\", \"miss\", \"mission\", \"mo\", \"money\", \"money\", \"money\", \"motiv\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"much\", \"name\", \"name\", \"name\", \"name\", \"narrat\", \"nasti\", \"nation\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"need\", \"nephew\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"never\", \"new\", \"new\", \"new\", \"new\", \"new\", \"next\", \"next\", \"next\", \"next\", \"next\", \"next\", \"next\", \"next\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nobodi\", \"nobodi\", \"nobodi\", \"noth\", \"noth\", \"noth\", \"noth\", \"noth\", \"number\", \"number\", \"number\", \"offer\", \"offic\", \"oh\", \"oh\", \"oh\", \"oh\", \"old\", \"old\", \"old\", \"old\", \"old\", \"old\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"open\", \"open\", \"open\", \"origin\", \"outlet\", \"page\", \"paint\", \"paint\", \"paint\", \"pant\", \"parker\", \"part\", \"part\", \"part\", \"part\", \"part\", \"parti\", \"pass\", \"pass\", \"pass\", \"pass\", \"passer\", \"passer\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"peopl\", \"per\", \"per\", \"per\", \"per\", \"pick\", \"pick\", \"pick\", \"pick\", \"pick\", \"place\", \"place\", \"place\", \"planet\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"play\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"player\", \"pleas\", \"pleas\", \"pleas\", \"pleas\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"poor\", \"pop\", \"pop\", \"pop\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"post\", \"potato\", \"precious\", \"prepar\", \"press\", \"press\", \"pretend\", \"prime\", \"prime\", \"prime\", \"prime\", \"princ\", \"probabl\", \"probabl\", \"probabl\", \"probabl\", \"probabl\", \"probabl\", \"probabl\", \"probabl\", \"process\", \"pull\", \"pull\", \"puppet\", \"put\", \"put\", \"put\", \"put\", \"put\", \"put\", \"qualiti\", \"qualiti\", \"question\", \"question\", \"question\", \"question\", \"quot\", \"quot\", \"rather\", \"rather\", \"rather\", \"reaction\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"read\", \"readi\", \"readi\", \"readi\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"realist\", \"realist\", \"realiti\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli\", \"realli\", \"record\", \"record\", \"record\", \"recruit\", \"recruit\", \"ref\", \"ref\", \"regard\", \"regular\", \"regular\", \"regular\", \"releas\", \"rememb\", \"rememb\", \"rememb\", \"rememb\", \"rememb\", \"remind\", \"remind\", \"remov\", \"replay\", \"repli\", \"respect\", \"respect\", \"respect\", \"respect\", \"retir\", \"retir\", \"retir\", \"rich\", \"rich\", \"ridicul\", \"ridicul\", \"ridicul\", \"ridicul\", \"ridicul\", \"ridicul\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"right\", \"rip\", \"risk\", \"room\", \"room\", \"rule\", \"sad\", \"sad\", \"sad\", \"sad\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"said\", \"salad\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"say\", \"school\", \"school\", \"school\", \"school\", \"score\", \"score\", \"score\", \"score\", \"score\", \"screen\", \"scrub\", \"season\", \"season\", \"season\", \"season\", \"season\", \"season\", \"season\", \"season\", \"season\", \"seat\", \"second\", \"second\", \"second\", \"second\", \"second\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"see\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"seen\", \"select\", \"sens\", \"sens\", \"sens\", \"sens\", \"sens\", \"serious\", \"serious\", \"serious\", \"serious\", \"shake\", \"shame\", \"shape\", \"share\", \"shook\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shoot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shot\", \"shoulder\", \"shut\", \"shut\", \"shut\", \"shut\", \"shut\", \"sick\", \"sign\", \"sign\", \"sign\", \"simpl\", \"situat\", \"situat\", \"situat\", \"skill\", \"skip\", \"skip\", \"skip\", \"sleep\", \"smile\", \"smile\", \"somebodi\", \"somebodi\", \"somebodi\", \"someon\", \"someon\", \"someon\", \"someon\", \"someon\", \"someon\", \"someon\", \"someon\", \"someon\", \"someth\", \"someth\", \"someth\", \"someth\", \"someth\", \"someth\", \"someth\", \"someth\", \"someth\", \"somewher\", \"somewher\", \"somewher\", \"space\", \"space\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"star\", \"statement\", \"statement\", \"stay\", \"stay\", \"stay\", \"step\", \"step\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"still\", \"stone\", \"straight\", \"straight\", \"straight\", \"straight\", \"straight\", \"straight\", \"streak\", \"streak\", \"sub\", \"sub\", \"subscrib\", \"suck\", \"sudden\", \"super\", \"super\", \"super\", \"super\", \"support\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"sure\", \"surpris\", \"surpris\", \"surpris\", \"surpris\", \"surpris\", \"system\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"talk\", \"tall\", \"tall\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"team\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"terri\", \"terribl\", \"terribl\", \"thank\", \"thank\", \"thank\", \"thank\", \"thank\", \"that\", \"that\", \"that\", \"that\", \"that\", \"that\", \"that\", \"that\", \"that\", \"that\", \"theyr\", \"theyr\", \"theyr\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"think\", \"third\", \"third\", \"tho\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thought\", \"thread\", \"thread\", \"thread\", \"thread\", \"thread\", \"threw\", \"thus\", \"tight\", \"til\", \"til\", \"till\", \"till\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tire\", \"tire\", \"today\", \"today\", \"toni\", \"tonight\", \"tonight\", \"tonight\", \"tonight\", \"tonight\", \"took\", \"took\", \"took\", \"took\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"touch\", \"touch\", \"touchdown\", \"trade\", \"trade\", \"trade\", \"trade\", \"train\", \"train\", \"trash\", \"treatment\", \"trigger\", \"trip\", \"tripl\", \"tripl\", \"trust\", \"trust\", \"turner\", \"twitter\", \"twitter\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"undef\", \"unguard\", \"unit\", \"unreal\", \"unreal\", \"unstopp\", \"updat\", \"us\", \"us\", \"us\", \"video\", \"video\", \"video\", \"video\", \"vision\", \"visit\", \"wade\", \"wade\", \"wade\", \"wade\", \"wade\", \"wade\", \"wade\", \"wade\", \"wade\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"wall\", \"wall\", \"wast\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"watch\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"welcom\", \"went\", \"went\", \"went\", \"went\", \"west\", \"west\", \"west\", \"wet\", \"what\", \"what\", \"what\", \"what\", \"what\", \"what\", \"whatev\", \"whatev\", \"whatev\", \"whatev\", \"whatev\", \"whatev\", \"white\", \"white\", \"wide\", \"wide\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"win\", \"wish\", \"wish\", \"wish\", \"wish\", \"wish\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"without\", \"woke\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"world\", \"world\", \"world\", \"world\", \"worri\", \"worst\", \"worst\", \"worth\", \"worth\", \"worth\", \"wow\", \"wow\", \"wow\", \"wow\", \"wow\", \"wow\", \"write\", \"write\", \"write\", \"ya\", \"ya\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"yeah\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yep\", \"yes\", \"yes\", \"yes\", \"yes\", \"yesterday\", \"yesterday\", \"yo\", \"yo\", \"younger\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 8, 6, 5, 2, 7, 4, 3, 10, 9]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el20901401097801558728007375358\", ldavis_el20901401097801558728007375358_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el20901401097801558728007375358\", ldavis_el20901401097801558728007375358_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el20901401097801558728007375358\", ldavis_el20901401097801558728007375358_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "0     -0.051493 -0.005656       1        1  17.891667\n",
       "7     -0.068342  0.014101       2        1  13.069484\n",
       "5     -0.035743 -0.013699       3        1   9.888963\n",
       "4     -0.070377 -0.058975       4        1   9.431428\n",
       "1     -0.082874 -0.050363       5        1   9.166373\n",
       "6      0.089967  0.041093       6        1   8.382241\n",
       "3     -0.002557  0.129411       7        1   8.372704\n",
       "2      0.082768  0.092074       8        1   8.316884\n",
       "9     -0.001495 -0.011377       9        1   8.013487\n",
       "8      0.140146 -0.136609      10        1   7.466769, topic_info=     Category       Freq      Term      Total  loglift  logprob\n",
       "term                                                           \n",
       "1510  Default  34.000000      nice  34.000000  30.0000  30.0000\n",
       "491   Default  33.000000   confirm  33.000000  29.0000  29.0000\n",
       "593   Default  46.000000      damn  46.000000  28.0000  28.0000\n",
       "696   Default  22.000000     doubl  22.000000  27.0000  27.0000\n",
       "1261  Default  20.000000      king  20.000000  26.0000  26.0000\n",
       "1458  Default  18.000000      miss  18.000000  25.0000  25.0000\n",
       "1390  Default  65.000000       man  65.000000  24.0000  24.0000\n",
       "2403  Default  16.000000     tripl  16.000000  23.0000  23.0000\n",
       "1382  Default  24.000000     magic  24.000000  22.0000  22.0000\n",
       "1897  Default  42.000000     right  42.000000  21.0000  21.0000\n",
       "1552  Default  20.000000        oh  20.000000  20.0000  20.0000\n",
       "1010  Default  26.000000       god  26.000000  19.0000  19.0000\n",
       "2331  Default  14.000000       tho  14.000000  18.0000  18.0000\n",
       "1367  Default  65.000000      love  65.000000  17.0000  17.0000\n",
       "1446  Default  15.000000   million  15.000000  16.0000  16.0000\n",
       "1985  Default  54.000000    season  54.000000  15.0000  15.0000\n",
       "1781  Default  18.000000  question  18.000000  14.0000  14.0000\n",
       "1842  Default  15.000000   regular  15.000000  13.0000  13.0000\n",
       "1045  Default  43.000000       guy  43.000000  12.0000  12.0000\n",
       "2382  Default  15.000000     trade  15.000000  11.0000  11.0000\n",
       "445   Default  25.000000     coach  25.000000  10.0000  10.0000\n",
       "1614  Default  27.000000      pass  27.000000   9.0000   9.0000\n",
       "1830  Default  14.000000    record  14.000000   8.0000   8.0000\n",
       "1875  Default  16.000000   respect  16.000000   7.0000   7.0000\n",
       "336   Default  28.000000      call  28.000000   6.0000   6.0000\n",
       "1415  Default  24.000000      mean  24.000000   5.0000   5.0000\n",
       "103   Default  23.000000     anyon  23.000000   4.0000   4.0000\n",
       "1278  Default  17.000000      lanc  17.000000   3.0000   3.0000\n",
       "2358  Default  15.000000     today  15.000000   2.0000   2.0000\n",
       "28    Default  11.000000        ad  11.000000   1.0000   1.0000\n",
       "...       ...        ...       ...        ...      ...      ...\n",
       "136   Topic10   1.836326  assassin   2.601165   2.2465  -6.4022\n",
       "1401  Topic10   1.772000    martin   2.536830   2.2359  -6.4379\n",
       "1462  Topic10   2.239007        mo   3.221734   2.2308  -6.2040\n",
       "1515  Topic10   6.359971    nobodi   9.640802   2.1787  -5.1600\n",
       "1875  Topic10  10.100956   respect  16.101310   2.1284  -4.6974\n",
       "2550  Topic10   5.587835      west   8.584732   2.1653  -5.2894\n",
       "736   Topic10   3.532103     earth   5.281132   2.1925  -5.7481\n",
       "1252  Topic10   3.969750       kat   6.067462   2.1705  -5.6313\n",
       "1278  Topic10   9.606736      lanc  17.530202   1.9932  -4.7475\n",
       "103   Topic10  11.903119     anyon  23.768682   1.9031  -4.5332\n",
       "2250  Topic10   6.523186     super  12.347907   1.9566  -5.1346\n",
       "2522  Topic10   3.774530      wall   6.325863   2.0783  -5.6817\n",
       "212   Topic10   5.995098    behind  12.764355   1.8390  -5.2191\n",
       "1312  Topic10   4.452740     legit   8.572849   1.9396  -5.5165\n",
       "2258  Topic10   4.457640   surpris   8.655915   1.9311  -5.5154\n",
       "1266  Topic10  10.888165      know  47.357496   1.1247  -4.6223\n",
       "740   Topic10   4.665654    easili   9.482974   1.8854  -5.4698\n",
       "1110  Topic10   4.447925      hold   9.409466   1.8454  -5.5176\n",
       "765   Topic10   5.365001       els  17.279312   1.4251  -5.3301\n",
       "904   Topic10   6.928210     first  41.065774   0.8151  -5.0744\n",
       "803   Topic10   7.846342      even  62.835738   0.5142  -4.9500\n",
       "1367  Topic10   7.264154      love  65.189549   0.4004  -5.0271\n",
       "1610  Topic10   4.775657      part  17.491671   1.2965  -5.4465\n",
       "155   Topic10   4.606636    averag  14.012753   1.4822  -5.4825\n",
       "1555  Topic10   5.865623       one  86.172865  -0.0925  -5.2409\n",
       "1375  Topic10   4.801877       lue  23.271354   1.0165  -5.4410\n",
       "2296  Topic10   5.129755      team  73.076715  -0.0617  -5.3749\n",
       "1821  Topic10   4.971871    realli  55.935356   0.1743  -5.4062\n",
       "2281  Topic10   4.740846      talk  26.653884   0.8680  -5.4538\n",
       "867   Topic10   4.709650       fan  23.097495   1.0046  -5.4604\n",
       "\n",
       "[639 rows x 6 columns], token_table=      Topic      Freq       Term\n",
       "term                            \n",
       "5         1  0.585297    absolut\n",
       "5         2  0.175589    absolut\n",
       "5         4  0.058530    absolut\n",
       "5         5  0.058530    absolut\n",
       "5         9  0.058530    absolut\n",
       "5        10  0.058530    absolut\n",
       "23        2  0.119211        act\n",
       "23        3  0.119211        act\n",
       "23        8  0.596056        act\n",
       "27        1  0.258663     actual\n",
       "27        2  0.143701     actual\n",
       "27        3  0.316143     actual\n",
       "27        4  0.028740     actual\n",
       "27        5  0.057481     actual\n",
       "27        6  0.057481     actual\n",
       "27        7  0.057481     actual\n",
       "27        8  0.086221     actual\n",
       "28        5  0.089215         ad\n",
       "28        7  0.892151         ad\n",
       "44        8  0.662394     afford\n",
       "47        8  0.728940      agenc\n",
       "52        1  0.939541       agre\n",
       "63       10  0.696296       aliv\n",
       "66        1  0.111310     almost\n",
       "66        3  0.055655     almost\n",
       "66        4  0.500894     almost\n",
       "66        5  0.222620     almost\n",
       "66        8  0.055655     almost\n",
       "70        1  0.080257    alreadi\n",
       "70        2  0.040129    alreadi\n",
       "...     ...       ...        ...\n",
       "2604      1  0.155214      write\n",
       "2604      3  0.620854      write\n",
       "2604     10  0.155214      write\n",
       "2608      2  0.170550         ya\n",
       "2608      7  0.682201         ya\n",
       "2610      1  0.159034       yeah\n",
       "2610      2  0.106023       yeah\n",
       "2610      5  0.106023       yeah\n",
       "2610      6  0.477103       yeah\n",
       "2610      9  0.053011       yeah\n",
       "2611      1  0.230293       year\n",
       "2611      2  0.345440       year\n",
       "2611      3  0.065798       year\n",
       "2611      4  0.065798       year\n",
       "2611      5  0.049349       year\n",
       "2611      6  0.032899       year\n",
       "2611      7  0.049349       year\n",
       "2611      8  0.049349       year\n",
       "2611      9  0.032899       year\n",
       "2611     10  0.049349       year\n",
       "2613      7  0.703954        yep\n",
       "2614      1  0.205200        yes\n",
       "2614      2  0.684001        yes\n",
       "2614      6  0.068400        yes\n",
       "2614      9  0.068400        yes\n",
       "2615      2  0.171727  yesterday\n",
       "2615      3  0.686910  yesterday\n",
       "2617      6  0.701340         yo\n",
       "2617      8  0.140268         yo\n",
       "2621      5  0.891931    younger\n",
       "\n",
       "[1842 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 8, 6, 5, 2, 7, 4, 3, 10, 9])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2 = CountVectorizer(#stop_words=stops, \n",
    "                     analyzer=english_corpus, \n",
    "                     min_df = 2, max_df = .95, #ngram_range=(1, 2),\n",
    "                     strip_accents='unicode', encoding='utf-8')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(**cv2.get_params())\n",
    "dtm_tfidf = tfidf_vectorizer.fit_transform(df_small_train.body)\n",
    "\n",
    "lda_tfidf = LatentDirichletAllocation(n_components=10, random_state=0)\n",
    "lda_tfidf.fit(dtm_tfidf)\n",
    "\n",
    "pyLDAvis.sklearn.prepare(lda_tfidf, dtm_tfidf, tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOPIC 0\n",
      "game\n",
      "cavs\n",
      "got\n",
      "\n",
      "TOPIC 1\n",
      "nice\n",
      "damn\n",
      "think\n",
      "\n",
      "TOPIC 2\n",
      "dont\n",
      "see\n",
      "game\n",
      "\n",
      "TOPIC 3\n",
      "game\n",
      "nba\n",
      "one\n",
      "\n",
      "TOPIC 4\n",
      "player\n",
      "finals\n",
      "team\n",
      "\n",
      "TOPIC 5\n",
      "team\n",
      "think\n",
      "player\n",
      "\n",
      "TOPIC 6\n",
      "one\n",
      "fucking\n",
      "people\n",
      "\n",
      "TOPIC 7\n",
      "double\n",
      "really\n",
      "seasons\n",
      "\n",
      "TOPIC 8\n",
      "man\n",
      "good\n",
      "confirmed\n",
      "\n",
      "TOPIC 9\n",
      "game\n",
      "games\n",
      "season\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def see_lda_topics(vectorizer, n_topics, fit_lda, n_examples):\n",
    "    '''\n",
    "    Prints top 10 names assigned to the topics, and the topics themselves\n",
    "    '''\n",
    "    vocab = vectorizer.get_feature_names()\n",
    "    for topic in range(n_topics):\n",
    "        print(f\"TOPIC {topic}\")\n",
    "        for j in np.argsort(-fit_lda.components_,1)[topic,:n_examples]:\n",
    "            print(vocab[j])\n",
    "        print()\n",
    "see_lda_topics(cv, 10, lda_tf, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abil',\n",
       " 'abl',\n",
       " 'about',\n",
       " 'abov',\n",
       " 'absolut',\n",
       " 'absorb',\n",
       " 'absurd',\n",
       " 'abus',\n",
       " 'accept',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'achiev',\n",
       " 'across',\n",
       " 'act',\n",
       " 'activ',\n",
       " 'actor',\n",
       " 'actual',\n",
       " 'ad',\n",
       " 'add',\n",
       " 'adjust',\n",
       " 'admit',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'advertis',\n",
       " 'advic',\n",
       " 'advoc',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'age',\n",
       " 'agenc',\n",
       " 'agent',\n",
       " 'aggress',\n",
       " 'ago',\n",
       " 'agre',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ai',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'albeit',\n",
       " 'alien',\n",
       " 'all',\n",
       " 'alley',\n",
       " 'almost',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alongsid',\n",
       " 'alreadi',\n",
       " 'also',\n",
       " 'altern',\n",
       " 'alway',\n",
       " 'am',\n",
       " 'amaz',\n",
       " 'ami',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amount',\n",
       " 'an',\n",
       " 'analysi',\n",
       " 'analyst',\n",
       " 'and',\n",
       " 'angl',\n",
       " 'angri',\n",
       " 'ani',\n",
       " 'anim',\n",
       " 'ankl',\n",
       " 'annoy',\n",
       " 'annual',\n",
       " 'anonym',\n",
       " 'anoth',\n",
       " 'answer',\n",
       " 'anti',\n",
       " 'anybodi',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'apart',\n",
       " 'appear',\n",
       " 'appl',\n",
       " 'appreci',\n",
       " 'appropri',\n",
       " 'are',\n",
       " 'arena',\n",
       " 'argu',\n",
       " 'argument',\n",
       " 'arm',\n",
       " 'around',\n",
       " 'art',\n",
       " 'articl',\n",
       " 'as',\n",
       " 'asham',\n",
       " 'asid',\n",
       " 'ask',\n",
       " 'aspect',\n",
       " 'ass',\n",
       " 'assassin',\n",
       " 'assist',\n",
       " 'assum',\n",
       " 'ast',\n",
       " 'at',\n",
       " 'athlet',\n",
       " 'athletic',\n",
       " 'attempt',\n",
       " 'attent',\n",
       " 'attest',\n",
       " 'autograph',\n",
       " 'averag',\n",
       " 'aw',\n",
       " 'awar',\n",
       " 'award',\n",
       " 'away',\n",
       " 'awesom',\n",
       " 'awkward',\n",
       " 'babi',\n",
       " 'back',\n",
       " 'background',\n",
       " 'backward',\n",
       " 'bad',\n",
       " 'bail',\n",
       " 'bald',\n",
       " 'ball',\n",
       " 'ballot',\n",
       " 'banana',\n",
       " 'bare',\n",
       " 'base',\n",
       " 'basebal',\n",
       " 'basic',\n",
       " 'basket',\n",
       " 'basketbal',\n",
       " 'battl',\n",
       " 'be',\n",
       " 'beach',\n",
       " 'beard',\n",
       " 'beast',\n",
       " 'beat',\n",
       " 'beater',\n",
       " 'beauti',\n",
       " 'becaus',\n",
       " 'becom',\n",
       " 'bed',\n",
       " 'been',\n",
       " 'beer',\n",
       " 'befor',\n",
       " 'begin',\n",
       " 'behind',\n",
       " 'believ',\n",
       " 'belov',\n",
       " 'below',\n",
       " 'ben',\n",
       " 'bench',\n",
       " 'bend',\n",
       " 'besid',\n",
       " 'best',\n",
       " 'bet',\n",
       " 'better',\n",
       " 'between',\n",
       " 'beyond',\n",
       " 'big',\n",
       " 'bigger',\n",
       " 'biggest',\n",
       " 'bill',\n",
       " 'bird',\n",
       " 'bit',\n",
       " 'bitch',\n",
       " 'bite',\n",
       " 'black',\n",
       " 'blake',\n",
       " 'blame',\n",
       " 'block',\n",
       " 'blood',\n",
       " 'blow',\n",
       " 'blown',\n",
       " 'blue',\n",
       " 'bo',\n",
       " 'board',\n",
       " 'boat',\n",
       " 'bob',\n",
       " 'bodi',\n",
       " 'bomb',\n",
       " 'book',\n",
       " 'booker',\n",
       " 'booti',\n",
       " 'boozer',\n",
       " 'bore',\n",
       " 'born',\n",
       " 'bosh',\n",
       " 'boston',\n",
       " 'both',\n",
       " 'bottom',\n",
       " 'bounc',\n",
       " 'bout',\n",
       " 'bowl',\n",
       " 'box',\n",
       " 'boy',\n",
       " 'brain',\n",
       " 'brand',\n",
       " 'break',\n",
       " 'brilliant',\n",
       " 'bring',\n",
       " 'broadcast',\n",
       " 'broke',\n",
       " 'broken',\n",
       " 'brook',\n",
       " 'brother',\n",
       " 'brought',\n",
       " 'brown',\n",
       " 'brush',\n",
       " 'bubbl',\n",
       " 'buddi',\n",
       " 'build',\n",
       " 'built',\n",
       " 'bull',\n",
       " 'bullet',\n",
       " 'bum',\n",
       " 'bunch',\n",
       " 'burden',\n",
       " 'burn',\n",
       " 'busi',\n",
       " 'bust',\n",
       " 'but',\n",
       " 'butler',\n",
       " 'butt',\n",
       " 'button',\n",
       " 'buy',\n",
       " 'buzzer',\n",
       " 'by',\n",
       " 'call',\n",
       " 'calm',\n",
       " 'came',\n",
       " 'camera',\n",
       " 'camp',\n",
       " 'can',\n",
       " 'candid',\n",
       " 'cannot',\n",
       " 'cant',\n",
       " 'cap',\n",
       " 'captain',\n",
       " 'card',\n",
       " 'care',\n",
       " 'career',\n",
       " 'carri',\n",
       " 'cartwright',\n",
       " 'case',\n",
       " 'cast',\n",
       " 'casual',\n",
       " 'catch',\n",
       " 'caught',\n",
       " 'caus',\n",
       " 'celebr',\n",
       " 'cell',\n",
       " 'center',\n",
       " 'centuri',\n",
       " 'certain',\n",
       " 'champion',\n",
       " 'championship',\n",
       " 'chanc',\n",
       " 'chang',\n",
       " 'charact',\n",
       " 'charg',\n",
       " 'chariti',\n",
       " 'chase',\n",
       " 'check',\n",
       " 'chemistri',\n",
       " 'cherish',\n",
       " 'chess',\n",
       " 'chest',\n",
       " 'child',\n",
       " 'chill',\n",
       " 'chip',\n",
       " 'choic',\n",
       " 'choos',\n",
       " 'chose',\n",
       " 'chosen',\n",
       " 'chunk',\n",
       " 'circl',\n",
       " 'citi',\n",
       " 'clap',\n",
       " 'class',\n",
       " 'classi',\n",
       " 'clear',\n",
       " 'click',\n",
       " 'clint',\n",
       " 'clip',\n",
       " 'close',\n",
       " 'closer',\n",
       " 'cloth',\n",
       " 'clown',\n",
       " 'clutch',\n",
       " 'coach',\n",
       " 'cock',\n",
       " 'coincid',\n",
       " 'cold',\n",
       " 'colin',\n",
       " 'collect',\n",
       " 'colleg',\n",
       " 'combin',\n",
       " 'come',\n",
       " 'comic',\n",
       " 'comment',\n",
       " 'commerci',\n",
       " 'commit',\n",
       " 'communiti',\n",
       " 'compani',\n",
       " 'compar',\n",
       " 'comparison',\n",
       " 'compet',\n",
       " 'competit',\n",
       " 'compil',\n",
       " 'complement',\n",
       " 'complet',\n",
       " 'compliment',\n",
       " 'concern',\n",
       " 'confer',\n",
       " 'confid',\n",
       " 'confirm',\n",
       " 'confus',\n",
       " 'consid',\n",
       " 'consist',\n",
       " 'conspiraci',\n",
       " 'constant',\n",
       " 'contact',\n",
       " 'contend',\n",
       " 'content',\n",
       " 'contest',\n",
       " 'context',\n",
       " 'continu',\n",
       " 'contract',\n",
       " 'contradictori',\n",
       " 'control',\n",
       " 'convers',\n",
       " 'convert',\n",
       " 'convinc',\n",
       " 'cool',\n",
       " 'copi',\n",
       " 'core',\n",
       " 'cornea',\n",
       " 'corner',\n",
       " 'correct',\n",
       " 'cost',\n",
       " 'could',\n",
       " 'count',\n",
       " 'coupl',\n",
       " 'cours',\n",
       " 'court',\n",
       " 'cover',\n",
       " 'cowherd',\n",
       " 'crack',\n",
       " 'crawl',\n",
       " 'crazi',\n",
       " 'creat',\n",
       " 'credit',\n",
       " 'crew',\n",
       " 'cri',\n",
       " 'cring',\n",
       " 'criteria',\n",
       " 'critic',\n",
       " 'cross',\n",
       " 'crowder',\n",
       " 'crown',\n",
       " 'crunch',\n",
       " 'crush',\n",
       " 'cultur',\n",
       " 'curios',\n",
       " 'curious',\n",
       " 'current',\n",
       " 'curri',\n",
       " 'cut',\n",
       " 'cute',\n",
       " 'dad',\n",
       " 'dagger',\n",
       " 'damn',\n",
       " 'dan',\n",
       " 'danc',\n",
       " 'dang',\n",
       " 'danger',\n",
       " 'dap',\n",
       " 'dare',\n",
       " 'date',\n",
       " 'day',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'death',\n",
       " 'debat',\n",
       " 'debut',\n",
       " 'decad',\n",
       " 'decent',\n",
       " 'decid',\n",
       " 'decis',\n",
       " 'declin',\n",
       " 'deep',\n",
       " 'defend',\n",
       " 'defens',\n",
       " 'defer',\n",
       " 'definit',\n",
       " 'degre',\n",
       " 'delet',\n",
       " 'delici',\n",
       " 'democrat',\n",
       " 'depth',\n",
       " 'derrick',\n",
       " 'deserv',\n",
       " 'despit',\n",
       " 'destroy',\n",
       " 'devast',\n",
       " 'dick',\n",
       " 'did',\n",
       " 'didnt',\n",
       " 'die',\n",
       " 'differ',\n",
       " 'difficult',\n",
       " 'dinner',\n",
       " 'direct',\n",
       " 'dirk',\n",
       " 'dirti',\n",
       " 'dis',\n",
       " 'disagre',\n",
       " 'disappear',\n",
       " 'disappoint',\n",
       " 'discuss',\n",
       " 'disgust',\n",
       " 'dislik',\n",
       " 'disrespect',\n",
       " 'distanc',\n",
       " 'distribut',\n",
       " 'do',\n",
       " 'doe',\n",
       " 'doesnt',\n",
       " 'dog',\n",
       " 'domin',\n",
       " 'don',\n",
       " 'done',\n",
       " 'dont',\n",
       " 'dope',\n",
       " 'doubl',\n",
       " 'doubt',\n",
       " 'down',\n",
       " 'dozen',\n",
       " 'draft',\n",
       " 'drag',\n",
       " 'drama',\n",
       " 'draw',\n",
       " 'dream',\n",
       " 'dri',\n",
       " 'dribbl',\n",
       " 'drink',\n",
       " 'drive',\n",
       " 'drop',\n",
       " 'drought',\n",
       " 'dub',\n",
       " 'duck',\n",
       " 'dude',\n",
       " 'due',\n",
       " 'dumb',\n",
       " 'dun',\n",
       " 'dunk',\n",
       " 'duo',\n",
       " 'durabl',\n",
       " 'durant',\n",
       " 'dure',\n",
       " 'duti',\n",
       " 'dynasti',\n",
       " 'each',\n",
       " 'earli',\n",
       " 'earth',\n",
       " 'easi',\n",
       " 'easier',\n",
       " 'easiest',\n",
       " 'easili',\n",
       " 'east',\n",
       " 'eastern',\n",
       " 'eat',\n",
       " 'edg',\n",
       " 'edit',\n",
       " 'effect',\n",
       " 'effici',\n",
       " 'effort',\n",
       " 'effortless',\n",
       " 'either',\n",
       " 'elbow',\n",
       " 'elect',\n",
       " 'elig',\n",
       " 'elit',\n",
       " 'els',\n",
       " 'elsewher',\n",
       " 'em',\n",
       " 'embarrass',\n",
       " 'encourag',\n",
       " 'end',\n",
       " 'endors',\n",
       " 'enemi',\n",
       " 'energi',\n",
       " 'enforc',\n",
       " 'enjoy',\n",
       " 'enough',\n",
       " 'enter',\n",
       " 'entertain',\n",
       " 'entir',\n",
       " 'epic',\n",
       " 'episod',\n",
       " 'equal',\n",
       " 'equat',\n",
       " 'er',\n",
       " 'era',\n",
       " 'eric',\n",
       " 'especi',\n",
       " 'essenti',\n",
       " 'even',\n",
       " 'event',\n",
       " 'eventu',\n",
       " 'ever',\n",
       " 'everi',\n",
       " 'everybodi',\n",
       " 'everyon',\n",
       " 'everyth',\n",
       " 'everywher',\n",
       " 'exact',\n",
       " 'exampl',\n",
       " 'excel',\n",
       " 'except',\n",
       " 'excit',\n",
       " 'excus',\n",
       " 'execut',\n",
       " 'exist',\n",
       " 'expect',\n",
       " 'experi',\n",
       " 'experienc',\n",
       " 'expert',\n",
       " 'explain',\n",
       " 'explan',\n",
       " 'expos',\n",
       " 'express',\n",
       " 'extend',\n",
       " 'extens',\n",
       " 'extent',\n",
       " 'extra',\n",
       " 'extraordinari',\n",
       " 'extrem',\n",
       " 'eye',\n",
       " 'fa',\n",
       " 'face',\n",
       " 'facilit',\n",
       " 'fact',\n",
       " 'factor',\n",
       " 'fail',\n",
       " 'fair',\n",
       " 'fake',\n",
       " 'fall',\n",
       " 'fals',\n",
       " 'fam',\n",
       " 'famili',\n",
       " 'fan',\n",
       " 'fanci',\n",
       " 'fantast',\n",
       " 'far',\n",
       " 'fast',\n",
       " 'faster',\n",
       " 'fat',\n",
       " 'father',\n",
       " 'fatigu',\n",
       " 'fault',\n",
       " 'favor',\n",
       " 'favorit',\n",
       " 'featur',\n",
       " 'feel',\n",
       " 'felt',\n",
       " 'few',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'figur',\n",
       " 'fill',\n",
       " 'film',\n",
       " 'final',\n",
       " 'find',\n",
       " 'fine',\n",
       " 'finger',\n",
       " 'finish',\n",
       " 'fire',\n",
       " 'first',\n",
       " 'fit',\n",
       " 'five',\n",
       " 'flak',\n",
       " 'flat',\n",
       " 'flex',\n",
       " 'fli',\n",
       " 'flip',\n",
       " 'floor',\n",
       " 'flow',\n",
       " 'fluke',\n",
       " 'focus',\n",
       " 'follow',\n",
       " 'fool',\n",
       " 'foot',\n",
       " 'footbal',\n",
       " 'footwork',\n",
       " 'for',\n",
       " 'forc',\n",
       " 'forev',\n",
       " 'forget',\n",
       " 'forgot',\n",
       " 'form',\n",
       " 'format',\n",
       " 'former',\n",
       " 'forward',\n",
       " 'foul',\n",
       " 'found',\n",
       " 'foundat',\n",
       " 'four',\n",
       " 'fourth',\n",
       " 'frame',\n",
       " 'franchis',\n",
       " 'frank',\n",
       " 'freak',\n",
       " 'free',\n",
       " 'freight',\n",
       " 'fresh',\n",
       " 'friend',\n",
       " 'from',\n",
       " 'front',\n",
       " 'full',\n",
       " 'fulli',\n",
       " 'fun',\n",
       " 'funni',\n",
       " 'futur',\n",
       " 'gabbi',\n",
       " 'gain',\n",
       " 'gambl',\n",
       " 'game',\n",
       " 'garbag',\n",
       " 'garnett',\n",
       " 'gave',\n",
       " 'gay',\n",
       " 'general',\n",
       " 'generat',\n",
       " 'genius',\n",
       " 'get',\n",
       " 'giant',\n",
       " 'gift',\n",
       " 'giggl',\n",
       " 'gilbert',\n",
       " 'girl',\n",
       " 'give',\n",
       " 'given',\n",
       " 'glad',\n",
       " 'glass',\n",
       " 'glorious',\n",
       " 'go',\n",
       " 'goal',\n",
       " 'goat',\n",
       " 'god',\n",
       " 'goe',\n",
       " 'golden',\n",
       " 'gone',\n",
       " 'good',\n",
       " 'goofi',\n",
       " 'goran',\n",
       " 'got',\n",
       " 'gotten',\n",
       " 'graduat',\n",
       " 'grammar',\n",
       " 'grant',\n",
       " 'great',\n",
       " 'green',\n",
       " 'griffin',\n",
       " 'group',\n",
       " 'grow',\n",
       " 'grown',\n",
       " 'guard',\n",
       " 'guess',\n",
       " 'gun',\n",
       " 'guy',\n",
       " 'gym',\n",
       " 'had',\n",
       " 'hair',\n",
       " 'hairlin',\n",
       " 'hakeem',\n",
       " 'half',\n",
       " 'halfway',\n",
       " 'hall',\n",
       " 'hand',\n",
       " 'handl',\n",
       " 'hang',\n",
       " 'happen',\n",
       " 'happi',\n",
       " 'hard',\n",
       " 'harden',\n",
       " 'hart',\n",
       " 'hat',\n",
       " 'hate',\n",
       " 'have',\n",
       " 'haven',\n",
       " 'havent',\n",
       " 'he',\n",
       " 'head',\n",
       " 'headlin',\n",
       " 'health',\n",
       " 'healthi',\n",
       " 'hear',\n",
       " 'heart',\n",
       " 'heat',\n",
       " 'heavi',\n",
       " 'heavili',\n",
       " 'height',\n",
       " 'hell',\n",
       " 'help',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hero',\n",
       " 'hey',\n",
       " 'hide',\n",
       " 'high',\n",
       " 'higher',\n",
       " 'highest',\n",
       " 'highlight',\n",
       " 'hilari',\n",
       " 'hill',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'hire',\n",
       " 'his',\n",
       " 'histor',\n",
       " 'histori',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'holi',\n",
       " 'home',\n",
       " 'honest',\n",
       " 'honor',\n",
       " 'hoop',\n",
       " 'hope',\n",
       " 'hors',\n",
       " 'host',\n",
       " 'hostag',\n",
       " 'hot',\n",
       " 'hour',\n",
       " 'hous',\n",
       " 'how',\n",
       " 'howev',\n",
       " 'huge',\n",
       " 'huh',\n",
       " 'human',\n",
       " 'humbl',\n",
       " 'hundr',\n",
       " 'hurt',\n",
       " 'ice',\n",
       " 'icon',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'ident',\n",
       " 'idiot',\n",
       " 'idol',\n",
       " 'if',\n",
       " 'ignor',\n",
       " 'ill',\n",
       " 'illeg',\n",
       " 'imag',\n",
       " 'imagin',\n",
       " 'immedi',\n",
       " 'impact',\n",
       " 'import',\n",
       " 'imposs',\n",
       " 'impress',\n",
       " 'improv',\n",
       " 'in',\n",
       " 'incid',\n",
       " 'includ',\n",
       " 'increas',\n",
       " 'incred',\n",
       " 'indic',\n",
       " 'individu',\n",
       " 'industri',\n",
       " 'influenc',\n",
       " 'inform',\n",
       " 'initi',\n",
       " 'injur',\n",
       " 'injuri',\n",
       " 'insan',\n",
       " 'insid',\n",
       " 'inspir',\n",
       " 'instant',\n",
       " 'instead',\n",
       " 'instinct',\n",
       " 'insult',\n",
       " 'intens',\n",
       " 'intent',\n",
       " 'interest',\n",
       " 'interview',\n",
       " 'into',\n",
       " 'involv',\n",
       " 'ironi',\n",
       " 'irrelev',\n",
       " 'is',\n",
       " 'iso',\n",
       " 'issu',\n",
       " 'it',\n",
       " 'itself',\n",
       " 'jack',\n",
       " 'jam',\n",
       " 'jazz',\n",
       " 'jealous',\n",
       " 'jeff',\n",
       " 'jerk',\n",
       " 'jerri',\n",
       " 'jersey',\n",
       " 'jimmi',\n",
       " 'job',\n",
       " 'join',\n",
       " 'joint',\n",
       " 'joke',\n",
       " 'jordan',\n",
       " 'judg',\n",
       " 'jump',\n",
       " 'jumper',\n",
       " 'juri',\n",
       " 'just',\n",
       " 'karma',\n",
       " 'kat',\n",
       " 'keep',\n",
       " 'kept',\n",
       " 'key',\n",
       " 'kick',\n",
       " 'kill',\n",
       " 'killer',\n",
       " 'kind',\n",
       " 'king',\n",
       " 'knew',\n",
       " 'knight',\n",
       " 'knock',\n",
       " 'know',\n",
       " 'knowledg',\n",
       " 'known',\n",
       " 'kyle',\n",
       " 'la',\n",
       " 'lanc',\n",
       " 'land',\n",
       " 'lane',\n",
       " 'languag',\n",
       " 'larg',\n",
       " 'larri',\n",
       " 'last',\n",
       " 'late',\n",
       " 'later',\n",
       " 'latest',\n",
       " 'laugh',\n",
       " 'laughabl',\n",
       " 'lawsuit',\n",
       " 'lazi',\n",
       " 'lead',\n",
       " 'leader',\n",
       " 'leadership',\n",
       " 'leagu',\n",
       " 'learn',\n",
       " 'least',\n",
       " 'leav',\n",
       " 'led',\n",
       " 'lee',\n",
       " 'left',\n",
       " 'leg',\n",
       " 'legaci',\n",
       " 'legend',\n",
       " 'legendari',\n",
       " 'legit',\n",
       " 'legitim',\n",
       " 'less',\n",
       " 'let',\n",
       " 'lethal',\n",
       " 'level',\n",
       " 'lie',\n",
       " 'life',\n",
       " 'lifetim',\n",
       " 'light',\n",
       " 'like',\n",
       " 'limit',\n",
       " 'lin',\n",
       " 'line',\n",
       " 'link',\n",
       " 'list',\n",
       " 'listen',\n",
       " 'liter',\n",
       " 'littl',\n",
       " 'live',\n",
       " 'lob',\n",
       " 'lock',\n",
       " 'locker',\n",
       " 'long',\n",
       " 'longer',\n",
       " 'longev',\n",
       " 'look',\n",
       " 'lord',\n",
       " 'lose',\n",
       " 'loss',\n",
       " 'lost',\n",
       " 'lot',\n",
       " 'loud',\n",
       " 'love',\n",
       " 'low',\n",
       " 'luck',\n",
       " 'lucki',\n",
       " 'ludicr',\n",
       " 'lue',\n",
       " 'luke',\n",
       " 'mac',\n",
       " 'machin',\n",
       " 'mad',\n",
       " 'made',\n",
       " 'magic',\n",
       " 'main',\n",
       " 'maintain',\n",
       " 'major',\n",
       " 'make',\n",
       " 'malleabl',\n",
       " 'mamba',\n",
       " 'man',\n",
       " 'mani',\n",
       " 'mansion',\n",
       " 'marc',\n",
       " 'margin',\n",
       " 'mark',\n",
       " 'market',\n",
       " 'martin',\n",
       " 'massiv',\n",
       " 'match',\n",
       " 'materi',\n",
       " 'matter',\n",
       " 'may',\n",
       " 'mayb',\n",
       " 'me',\n",
       " 'mean',\n",
       " 'meaningless',\n",
       " 'meant',\n",
       " 'media',\n",
       " 'meet',\n",
       " 'member',\n",
       " 'memor',\n",
       " 'memori',\n",
       " 'men',\n",
       " 'mental',\n",
       " 'mention',\n",
       " 'mentor',\n",
       " 'mess',\n",
       " 'met',\n",
       " 'mid',\n",
       " 'middl',\n",
       " 'might',\n",
       " 'mike',\n",
       " 'mil',\n",
       " 'mileag',\n",
       " 'mileston',\n",
       " 'miller',\n",
       " 'million',\n",
       " 'min',\n",
       " 'mind',\n",
       " 'minimum',\n",
       " 'minor',\n",
       " 'minut',\n",
       " 'miser',\n",
       " 'miss',\n",
       " 'mo',\n",
       " 'mobil',\n",
       " 'mode',\n",
       " 'model',\n",
       " 'modern',\n",
       " 'moment',\n",
       " 'mon',\n",
       " 'money',\n",
       " 'monster',\n",
       " 'month',\n",
       " 'moon',\n",
       " 'more',\n",
       " 'most',\n",
       " 'mother',\n",
       " 'motion',\n",
       " 'motiv',\n",
       " 'mouth',\n",
       " 'move',\n",
       " 'movement',\n",
       " 'movi',\n",
       " 'much',\n",
       " 'multipl',\n",
       " 'muscl',\n",
       " 'music',\n",
       " 'must',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'name',\n",
       " 'narrat',\n",
       " 'nash',\n",
       " 'nasti',\n",
       " 'nation',\n",
       " 'natur',\n",
       " 'neal',\n",
       " 'near',\n",
       " 'neck',\n",
       " 'need',\n",
       " 'negat',\n",
       " 'neither',\n",
       " 'net',\n",
       " 'never',\n",
       " 'new',\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "X = cv.fit_transform(sentences[:500])\n",
    "Z = pd.DataFrame(X.toarray(),columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1790)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(stop_words='english')\n",
    "XX = cv2.fit_transform(words[:500])\n",
    "Z = pd.DataFrame(XX.toarray(),columns=cv2.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf = TfidfVectorizer(stop_words='english')\n",
    "X3 = tf.fit_transform(sentences[:500])\n",
    "Z = pd.DataFrame(X3.toarray(), columns = tf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1790)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25798    [As much hate as this dude gets, their is no denying that he can ball, and he's breaking these records at a relative...\n",
       "26644                [The last 9 finals have consisted of either LeBron James Jones or Kobe Bryant, but never at the same time.]\n",
       "5307                                                                                                        [That's just unfair]\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize\n",
    "text = df.body.apply(sent_tokenize)\n",
    "text.sample(3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25798    [As, much, hate, as, this, dude, gets, ,, their, is, no, denying, that, he, can, ball, ,, and, he, 's, breaking, the...\n",
       "26644    [The, last, 9, finals, have, consisted, of, either, LeBron, James, Jones, or, Kobe, Bryant, ,, but, never, at, the, ...\n",
       "5307                                                                                                    [That, 's, just, unfair]\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "words = df.body.apply(word_tokenize)\n",
    "words.sample(3, random_state=42)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>16</th>\n",
       "      <th>added</th>\n",
       "      <th>ago</th>\n",
       "      <th>akron</th>\n",
       "      <th>april</th>\n",
       "      <th>believe</th>\n",
       "      <th>better</th>\n",
       "      <th>chugging</th>\n",
       "      <th>come</th>\n",
       "      <th>considered</th>\n",
       "      <th>...</th>\n",
       "      <th>retired</th>\n",
       "      <th>retires</th>\n",
       "      <th>rose</th>\n",
       "      <th>said</th>\n",
       "      <th>smhhhh</th>\n",
       "      <th>teenager</th>\n",
       "      <th>think</th>\n",
       "      <th>wait</th>\n",
       "      <th>workaholic</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows  57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   16  added  ago  akron  april  believe  better  chugging  come  considered  \\\n",
       "0   0      1    0      0      0        0       0         0     0           0   \n",
       "1   0      0    0      0      0        0       0         1     0           1   \n",
       "2   0      0    0      0      0        0       0         0     0           0   \n",
       "3   0      0    0      0      0        0       0         0     0           0   \n",
       "4   0      0    0      0      0        0       0         0     0           0   \n",
       "5   0      0    0      0      1        0       1         0     1           0   \n",
       "6   0      0    0      0      0        0       0         0     0           0   \n",
       "7   1      0    1      1      0        1       0         0     0           0   \n",
       "8   0      0    0      0      0        0       0         0     0           0   \n",
       "9   1      0    0      0      0        0       0         0     0           0   \n",
       "\n",
       "   ...    retired  retires  rose  said  smhhhh  teenager  think  wait  \\\n",
       "0  ...          0        0     0     0       0         0      0     1   \n",
       "1  ...          1        0     0     0       0         0      1     0   \n",
       "2  ...          0        0     0     0       0         0      0     0   \n",
       "3  ...          0        0     0     0       0         0      0     0   \n",
       "4  ...          0        0     0     0       1         0      0     0   \n",
       "5  ...          0        0     0     0       0         0      0     0   \n",
       "6  ...          0        0     1     0       0         0      0     0   \n",
       "7  ...          0        0     0     0       0         1      0     0   \n",
       "8  ...          0        1     0     1       0         0      0     0   \n",
       "9  ...          0        0     0     0       0         0      0     0   \n",
       "\n",
       "   workaholic  years  \n",
       "0           0      0  \n",
       "1           0      0  \n",
       "2           0      0  \n",
       "3           0      0  \n",
       "4           0      0  \n",
       "5           1      0  \n",
       "6           0      1  \n",
       "7           0      1  \n",
       "8           0      0  \n",
       "9           0      0  \n",
       "\n",
       "[10 rows x 57 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "X = cv.fit_transform(df.body[90:100])\n",
    "pd.DataFrame(X.toarray(),columns=cv.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = joblib.load('data/clean/clean_df.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "\n",
    "sia = SIA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_selected = 2/16\n",
    "num_trial = 27"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3882570868012486"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of num of trials up to and until 1st success\n",
    "P = ((1-prob_selected)**(num_trial-1)) * prob_selected\n",
    "P * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33972495095109256"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# probability of num of failures until 1st success\n",
    "P2 = ((1-prob_selected)**(num_trial)) * prob_selected\n",
    "P2 * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
